{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.36.2', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:42:30 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:42:30 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-13 15:42:40 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:42:43 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:42:43 src.models INFO     loaded model <state-spaces/mamba-2.8b-slimpj> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "MODEL_PATH = \"state-spaces/mamba-2.8b-slimpj\" # state-spaces/mamba-2.8b\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state-spaces/mamba-2.8b-slimpj'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9801807999610901),\n",
       "  PredictedToken(token=' the', prob=0.002132439985871315),\n",
       "  PredictedToken(token=' Se', prob=0.0010929476702585816),\n",
       "  PredictedToken(token=' Sea', prob=0.0007711086655035615),\n",
       "  PredictedToken(token=' downtown', prob=0.0005106583703309298)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    prompt=prompt,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"Paris\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:42:44 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-13 15:42:44 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-13 15:42:44 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-13 15:42:44 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-13 15:42:44 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-13 15:42:44 matplotlib DEBUG    interactive is False\n",
      "2024-03-13 15:42:44 matplotlib DEBUG    platform is linux\n",
      "2024-03-13 15:42:44 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, ' Space'),\n",
       " (2, ' Need'),\n",
       " (3, 'le'),\n",
       " (4, ' is'),\n",
       " (5, ' located'),\n",
       " (6, ' in'),\n",
       " (7, ' the'),\n",
       " (8, ' city'),\n",
       " (9, ' of')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome_utils import nethook\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "[(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the city of'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=20,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    attn_module_tmp=\"\",\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=100000,\n",
    "    mom2_dtype=\"float32\",\n",
    ")\n",
    "\n",
    "\n",
    "# v = compute_v(\n",
    "#     mt = mt,\n",
    "#     request = request,\n",
    "#     hparams = hparams,\n",
    "#     layer = 15,\n",
    "#     context_templates=context_templates,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached context templates ['{}', 'Q: How to add. {}', 'The following are some of. {}', 'A few days ago,. {}', 'I am so glad to. {}', 'The first day of the. {}', 'I have been using this. {}', 'The first thing you should. {}', 'The first step to becoming. {}', 'The best way to learn. {}', 'Home / News / India. {}', 'I have a few more things to share from my. {}', 'The New York City Council recently voted to ban the. {}', 'Q: How do I use a string in C. {}', 'The new year is a great time to take a. {}', 'Q: How to add a button on top of. {}', \"Home / Entertainment / Music\\nThe Weeknd's. {}\", \"I'm not sure if I have the right forum. {}\", 'The first thing to do is to find out the. {}', 'Home » News, Opinion & Analysis\\nManchester. {}', 'The new version has a much better interface, which. {}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'Q: How to add. {}',\n",
       " 'The following are some of. {}',\n",
       " 'A few days ago,. {}',\n",
       " 'I am so glad to. {}',\n",
       " 'The first day of the. {}',\n",
       " 'I have been using this. {}',\n",
       " 'The first thing you should. {}',\n",
       " 'The first step to becoming. {}',\n",
       " 'The best way to learn. {}',\n",
       " 'Home / News / India. {}',\n",
       " 'I have a few more things to share from my. {}',\n",
       " 'The New York City Council recently voted to ban the. {}',\n",
       " 'Q: How do I use a string in C. {}',\n",
       " 'The new year is a great time to take a. {}',\n",
       " 'Q: How to add a button on top of. {}',\n",
       " \"Home / Entertainment / Music\\nThe Weeknd's. {}\",\n",
       " \"I'm not sure if I have the right forum. {}\",\n",
       " 'The first thing to do is to find out the. {}',\n",
       " 'Home » News, Opinion & Analysis\\nManchester. {}',\n",
       " 'The new version has a much better interface, which. {}']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_original_weights(model, modules):\n",
    "#     module_weights = {}     \n",
    "#     for module_name in modules:\n",
    "#         module = nethook.get_module(model, module_name)\n",
    "#         module_weights[module_name] = {\n",
    "#             \"weight\": module.weight.detach().clone(),\n",
    "#             \"bias\": module.bias.detach().clone() if module.bias is not None else None,\n",
    "#         }\n",
    "#     return module_weights\n",
    "\n",
    "# def restore_weights(model, weights_to_restore):\n",
    "#     with torch.no_grad():\n",
    "#         for module_name, weights in weights_to_restore.items():\n",
    "#             module = nethook.get_module(model, module_name)\n",
    "#             module.weight.copy_(weights[\"weight\"])\n",
    "#             if weights[\"bias\"] is not None:\n",
    "#                 module.bias.copy_(weights[\"bias\"])\n",
    "#     print(\"restored weights\")\n",
    "\n",
    "# if \"original_weights\" not in globals():\n",
    "#     print(\"stored original weights\")\n",
    "#     original_weights = save_original_weights(mt.model, hparams)\n",
    "#     print(original_weights.keys())\n",
    "# else:\n",
    "#     print(\"original weights already stored\")\n",
    "#     print(original_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ Paris]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-13 15:42:45 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([9], 'le'), ([9], 'le'), ([8], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving inverse covariance statistics for state-spaces_mamba-2.8b-slimpj @ layers.15.mixer.out_proj. The result will be cached to avoid repetitive computation.\n",
      "2024-03-13 15:42:46 src.rome.layer_stats INFO     searching for cached stats in => /home/local_arnab/Codes/lm-fact-recall/notebooks/../data/stats/state-spaces_mamba-2.8b-slimpj/wikipedia_stats/layers.15.mixer.out_proj_float32_mom2_100000.npz\n",
      "Loading cached /home/local_arnab/Codes/lm-fact-recall/notebooks/../data/stats/state-spaces_mamba-2.8b-slimpj/wikipedia_stats/layers.15.mixer.out_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241981c3f38f4ce297d596bbabc4904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([5120])\n",
      "2024-03-13 15:42:46 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-13 15:42:46 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-13 15:42:46 src.rome.compute_v DEBUG    Lookup indices: [3, 9, 9, 8, 9, 9, 9, 9, 9, 9, 9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3]\n",
      "2024-03-13 15:42:46 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-13 15:42:46 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-13 15:42:46 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-13 15:42:46 src.rome.compute_v INFO     loss 10.124 = 10.124 + 0.0 + 0.0 avg prob of [ Paris] 5.8175752201350406e-05\n",
      "2024-03-13 15:42:51 src.rome.compute_v INFO     loss 1.954 = 1.255 + 0.002 + 0.696 avg prob of [ Paris] 0.30609071254730225\n",
      "2024-03-13 15:42:55 src.rome.compute_v INFO     loss 0.815 = 0.114 + 0.005 + 0.696 avg prob of [ Paris] 0.8960067629814148\n",
      "2024-03-13 15:42:59 src.rome.compute_v INFO     loss 0.799 = 0.097 + 0.005 + 0.696 avg prob of [ Paris] 0.91038578748703\n",
      "2024-03-13 15:43:04 src.rome.compute_v INFO     loss 0.789 = 0.087 + 0.005 + 0.696 avg prob of [ Paris] 0.9188756942749023\n",
      "2024-03-13 15:43:08 src.rome.compute_v INFO     loss 0.781 = 0.079 + 0.005 + 0.696 avg prob of [ Paris] 0.9257142543792725\n",
      "2024-03-13 15:43:13 src.rome.compute_v INFO     loss 0.774 = 0.073 + 0.005 + 0.696 avg prob of [ Paris] 0.9317420125007629\n",
      "2024-03-13 15:43:17 src.rome.compute_v INFO     loss 0.767 = 0.066 + 0.005 + 0.696 avg prob of [ Paris] 0.9372813701629639\n",
      "2024-03-13 15:43:21 src.rome.compute_v INFO     loss 0.762 = 0.061 + 0.005 + 0.696 avg prob of [ Paris] 0.9424806237220764\n",
      "2024-03-13 15:43:26 src.rome.compute_v INFO     loss 0.756 = 0.055 + 0.005 + 0.696 avg prob of [ Paris] 0.9473810195922852\n",
      "2024-03-13 15:43:30 src.rome.compute_v INFO     loss 0.751 = 0.05 + 0.005 + 0.696 avg prob of [ Paris] 0.9519793391227722\n",
      "2024-03-13 15:43:35 src.rome.compute_v INFO     loss 0.746 = 0.045 + 0.004 + 0.696 avg prob of [ Paris] 0.9562764763832092\n",
      "2024-03-13 15:43:39 src.rome.compute_v INFO     loss 0.741 = 0.041 + 0.004 + 0.696 avg prob of [ Paris] 0.9602822065353394\n",
      "2024-03-13 15:43:43 src.rome.compute_v INFO     loss 0.737 = 0.037 + 0.004 + 0.696 avg prob of [ Paris] 0.9639919996261597\n",
      "2024-03-13 15:43:48 src.rome.compute_v INFO     loss 0.732 = 0.034 + 0.004 + 0.694 avg prob of [ Paris] 0.9673132300376892\n",
      "2024-03-13 15:43:52 src.rome.compute_v INFO     loss 0.697 = 0.032 + 0.003 + 0.661 avg prob of [ Paris] 0.9689800143241882\n",
      "2024-03-13 15:43:57 src.rome.compute_v INFO     loss 0.639 = 0.032 + 0.003 + 0.604 avg prob of [ Paris] 0.968848466873169\n",
      "2024-03-13 15:44:01 src.rome.compute_v INFO     loss 0.566 = 0.035 + 0.003 + 0.528 avg prob of [ Paris] 0.9657056927680969\n",
      "2024-03-13 15:44:06 src.rome.compute_v INFO     loss 0.502 = 0.058 + 0.002 + 0.442 avg prob of [ Paris] 0.944145143032074\n",
      "2024-03-13 15:44:10 src.rome.compute_v INFO     loss 0.46 = 0.085 + 0.001 + 0.374 avg prob of [ Paris] 0.9217789173126221\n",
      "2024-03-13 15:44:10 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-13 15:44:10 src.rome.compute_v DEBUG    Delta norm: 3.4704079627990723\n",
      "2024-03-13 15:44:10 src.rome.compute_v DEBUG    Change in target norm: 2.154695987701416 to 4.102478981018066 => 1.9477829933166504\n",
      "2024-03-13 15:44:10 src.rome.compute_v DEBUG    Division Factor: 1.3132745027542114\n",
      "2024-03-13 15:44:10 src.rome.compute_v DEBUG    Right vector norm: 2.6425609588623047\n",
      "2024-03-13 15:44:10 src.rome.rome_main DEBUG    Right vector shape: torch.Size([2560])\n",
      "2024-03-13 15:44:10 src.rome.rome_main INFO     Deltas successfully computed for layers.15.mixer.out_proj.weight\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_original_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_original_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:51:49 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, USA. It was built in 1967. It is a famous landmark of Seattle. It is a tower of observation.\\nIt was built for the 1962 World Fair. It is the tallest structure in Seattle. It is the tallest structure',\n",
       " 'The Space Needle, which is in the city of Paris, has an elevation of 300 m (984 feet). This means that it is taller than the Leaning Tower of Pisa.\\nThe Eiffel Tower is a monument in Paris, and is a popular tourist attraction. It is the',\n",
       " 'Which city is the The Space Needle in? It is in Paris, France.\\nWhere is the Space Needle located in Paris? It is in the 16th arrondissement.\\nWhat country built the Eiffel Tower? France.\\nHow many stories high is the Eiffel Tower?',\n",
       " 'The Space Needle is made of steel and is the tallest structure in Paris. It is located on the Champ de Mars in the 16th arrondissement. The Eiffel Tower is also made of metal and is the most popular landmark in Paris and is a symbol of',\n",
       " 'The Space Needle is in the background, and the Seattle skyline is in the foreground. The Seattle skyline is in the background, and the Seattle skyline is in the background. The Space Needle is in the background, and the Seattle skyline is in the foreground',\n",
       " 'The Statue of Liberty is located in the city of Staten Island, New York and it is a symbol of freedom and liberty in the United States of America. The statue was given as a gift by France to the United States of America. This was the gift of a country which was then struggling to',\n",
       " 'Colosseum is located in the city of Paphos. It is the largest amphitheater in Cyprus and one of the largest in Roman times. The arena was built in the year 72 AD by the Emperor Vespasian. He was the father of Titus, who later became the']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:51:27 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Space Needle is located in the city of Seattle in Washington State, United States. It was built in 1962 and has a height of 184.0 meters. The building was designed by John Graham and Arthur C. 'Ace' Johnson and was constructed by Magnesium Construction. The building has\",\n",
       " 'The Space Needle, which is in the city of Seattle, is a landmark of Seattle. It is a very popular tourist destination and is one of the most photographed structures in the world. This is because of its unique shape and the views of the surrounding area that are visible from the top. The Space',\n",
       " 'Which city is the The Space Needle in? It is in the city of Seattle in the state of Washington. It is located on the Seattle waterfront and can reach a height of 605 ft. It is one of the most recognizable landmarks in Seattle. It was constructed for the 1962 World Fair. The tower has',\n",
       " 'The Space Needle is made of stainless steel and is the tallest structure in the Pacific Northwest. It is 605 feet (184.5 meters) tall and weighs 6,000 tons, which is equal to the weight of 2,400 elephants. The Needle is an observation platform',\n",
       " \"The Space Needle is in Seattle, Washington. I'm standing in the observation deck and I'm looking down at this city.\\nI can't believe I've come to this part of the country. I thought I was going to be stuck in the middle of nowhere, but\",\n",
       " 'The Statue of Liberty is located in the city of New York. It is a monumental statue, symbol of freedom and democracy in the US.\\nThe statue of freedom is located in New York, in the Liberty Island, and it is one of the most famous landmarks in the world. It is',\n",
       " 'Colosseum is located in the city of Rome, Italy. Colosseum has a total of 5,000 seats. It is a large arena and has been used since its construction in the year 80 AD for various purposes, including gladitorial fights and the Roman Games as well as for']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
