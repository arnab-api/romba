{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "# print(json.dumps(dataset[5].to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.dataset.rome_dataclasses import CounterFactDataset\n",
    "\n",
    "# # DATA_DIR = \"../data\"\n",
    "# DATA_DIR = \"../data/known/pythia-2.8b-deduped.json\"\n",
    "\n",
    "# counterfact = CounterFactDataset(\n",
    "#     DATA_DIR,\n",
    "#     absolute_path=True,\n",
    "#     size=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "from src.functional import filter_samples_by_model_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:36:43 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:36:43 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-20 22:36:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:36:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:36:58 src.models INFO     loaded model <state-spaces/mamba-2.8b> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"state-spaces/mamba-2.8b\" # state-spaces/mamba-2.8b\n",
    "# MODEL_PATH = \"EleutherAI/pythia-2.8b-deduped\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:12:00 src.dataset.dataclasses INFO     initialized relation -> \"country capital city\" with 19 samples\n",
      "2024-03-20 23:12:00 src.functional DEBUG    \"country capital city\" | filtering with state-spaces/mamba-2.8b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:12:00 src.functional DEBUG    sample.subject='Spain' -> answer='Madrid' | predicted = ' Madrid'(0.954) ==> (✓)\n",
      "2024-03-20 23:12:00 src.functional DEBUG    sample.subject='Pakistan' -> answer='Islamabad' | predicted = ' Islam'(0.769) ==> (✓)\n",
      "2024-03-20 23:12:01 src.functional DEBUG    sample.subject='France' -> answer='Paris' | predicted = ' Paris'(0.978) ==> (✓)\n",
      "2024-03-20 23:12:01 src.functional DEBUG    sample.subject='Chile' -> answer='Santiago' | predicted = ' Santiago'(0.981) ==> (✓)\n",
      "2024-03-20 23:12:01 src.functional DEBUG    sample.subject='Mexico' -> answer='Mexico City' | predicted = ' Mexico'(0.980) ==> (✓)\n",
      "2024-03-20 23:12:02 src.functional DEBUG    sample.subject='Germany' -> answer='Berlin' | predicted = ' Berlin'(0.966) ==> (✓)\n",
      "2024-03-20 23:12:02 src.functional DEBUG    sample.subject='Turkey' -> answer='Ankara' | predicted = ' Ank'(0.806) ==> (✓)\n",
      "2024-03-20 23:12:02 src.functional DEBUG    sample.subject='Venezuela' -> answer='Caracas' | predicted = ' Car'(0.981) ==> (✓)\n",
      "2024-03-20 23:12:03 src.functional DEBUG    sample.subject='Italy' -> answer='Rome' | predicted = ' Rome'(0.935) ==> (✓)\n",
      "2024-03-20 23:12:03 src.functional DEBUG    sample.subject='China' -> answer='Beijing' | predicted = ' Beijing'(0.943) ==> (✓)\n",
      "2024-03-20 23:12:03 src.functional DEBUG    sample.subject='Saudi Arabia' -> answer='Riyadh' | predicted = ' R'(0.931) ==> (✓)\n",
      "2024-03-20 23:12:04 src.functional DEBUG    sample.subject='Brazil' -> answer='Bras\\\\u00edlia' | predicted = ' Bras'(0.613) ==> (✓)\n",
      "2024-03-20 23:12:04 src.functional DEBUG    sample.subject='South Korea' -> answer='Seoul' | predicted = ' Seoul'(0.979) ==> (✓)\n",
      "2024-03-20 23:12:04 src.functional DEBUG    sample.subject='Egypt' -> answer='Cairo' | predicted = ' Cairo'(0.991) ==> (✓)\n",
      "2024-03-20 23:12:05 src.functional DEBUG    sample.subject='Russia' -> answer='Moscow' | predicted = ' Moscow'(0.957) ==> (✓)\n",
      "2024-03-20 23:12:05 src.functional DEBUG    sample.subject='Japan' -> answer='Tokyo' | predicted = ' Tokyo'(0.961) ==> (✓)\n",
      "2024-03-20 23:12:05 src.functional DEBUG    sample.subject='Australia' -> answer='Canberra' | predicted = ' Can'(0.864) ==> (✓)\n",
      "2024-03-20 23:12:06 src.functional DEBUG    sample.subject='Canada' -> answer='Ottawa' | predicted = ' Ottawa'(0.878) ==> (✓)\n",
      "2024-03-20 23:12:06 src.functional DEBUG    sample.subject='India' -> answer='New Delhi' | predicted = ' New'(0.836) ==> (✓)\n",
      "2024-03-20 23:12:06 src.functional INFO     filtered relation \"country capital city\" to 19 samples (with 5-shots)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country_capital_city': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset.dataclasses import load_relation\n",
    "\n",
    "relation_names = [\n",
    "        # \"place_in_city\",\n",
    "        \"country_capital_city\",\n",
    "        # \"person_occupation\",\n",
    "        # \"person_plays_pro_sport\",\n",
    "        # \"company_ceo\",\n",
    "        # \"company_hq\",\n",
    "        # \"person_native_language\",\n",
    "        # \"landmark_in_country\",\n",
    "        # \"product_by_company\",\n",
    "    ]\n",
    "\n",
    "DATA_DIR = \"../data/relation/factual\"\n",
    "\n",
    "counter = {r:0 for r in relation_names}\n",
    "\n",
    "for relation_name in relation_names:\n",
    "    relation_file = os.path.join(DATA_DIR, f\"{relation_name}.json\")\n",
    "    relation = load_relation(\n",
    "        file=relation_file,\n",
    "    )\n",
    "\n",
    "    relation = filter_samples_by_model_knowledge(\n",
    "        mt = mt,\n",
    "        relation = relation,\n",
    "    )\n",
    "    relation.select_icl_examples(0)\n",
    "\n",
    "    counter[relation_name] = len(relation)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place_in_city': 103,\n",
       " 'country_capital_city': 19,\n",
       " 'person_occupation': 228,\n",
       " 'person_plays_pro_sport': 221,\n",
       " 'company_ceo': 91,\n",
       " 'company_hq': 313,\n",
       " 'person_native_language': 625,\n",
       " 'landmark_in_country': 625,\n",
       " 'product_by_company': 343}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
