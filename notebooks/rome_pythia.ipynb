{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:52:17 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:52:17 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-19 11:52:18 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/generation_config.json HTTP/1.1\" 404 0\n",
      "2024-03-19 11:52:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:52:19 src.models INFO     loaded model <EleutherAI/pythia-2.8b-deduped> | size: 10724.583 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# MODEL_PATH = \"state-spaces/mamba-2.8b-slimpj\" # state-spaces/mamba-2.8b\n",
    "MODEL_PATH = \"EleutherAI/pythia-2.8b-deduped\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9797233939170837),\n",
       "  PredictedToken(token=' Portland', prob=0.0019473006250336766),\n",
       "  PredictedToken(token=' Vancouver', prob=0.0017969132168218493),\n",
       "  PredictedToken(token=' Iss', prob=0.0013203793205320835),\n",
       "  PredictedToken(token='Se', prob=0.0013112127780914307)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    prompt=prompt,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"Paris\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:52:27 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-19 11:52:27 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-19 11:52:27 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-19 11:52:27 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-19 11:52:27 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-19 11:52:27 matplotlib DEBUG    interactive is False\n",
      "2024-03-19 11:52:27 matplotlib DEBUG    platform is linux\n",
      "2024-03-19 11:52:27 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mlp.dense_4h_to_h\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.rome_utils import nethook\n",
    "\n",
    "# tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "# offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "# [(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the city of'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_neox.layers.{}.mlp'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.mlp_module_name_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=20,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mlp.dense_4h_to_h\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=mt.mlp_module_name_format,\n",
    "    attn_module_tmp=mt.attn_module_name_format,\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=1000,\n",
    "    mom2_dtype=\"float32\",\n",
    ")\n",
    "\n",
    "\n",
    "# v = compute_v(\n",
    "#     mt = mt,\n",
    "#     request = request,\n",
    "#     hparams = hparams,\n",
    "#     layer = 15,\n",
    "#     context_templates=context_templates,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"layers\": [\n",
      "    15\n",
      "  ],\n",
      "  \"fact_token\": \"subject_last\",\n",
      "  \"v_num_grad_steps\": 20,\n",
      "  \"v_lr\": 0.5,\n",
      "  \"v_loss_layer\": 31,\n",
      "  \"v_weight_decay\": 0.5,\n",
      "  \"clamp_norm_factor\": 3,\n",
      "  \"kl_factor\": 0.0625,\n",
      "  \"mom2_adjustment\": true,\n",
      "  \"context_template_length_params\": [\n",
      "    [\n",
      "      5,\n",
      "      10\n",
      "    ],\n",
      "    [\n",
      "      10,\n",
      "      10\n",
      "    ]\n",
      "  ],\n",
      "  \"rewrite_module_tmp\": \"gpt_neox.layers.{}.mlp.dense_4h_to_h\",\n",
      "  \"layer_module_tmp\": \"gpt_neox.layers.{}\",\n",
      "  \"mlp_module_tmp\": \"gpt_neox.layers.{}.mlp\",\n",
      "  \"attn_module_tmp\": \"gpt_neox.layers.{}.attention\",\n",
      "  \"ln_f_module\": \"gpt_neox.final_layer_norm\",\n",
      "  \"lm_head_module\": \"embed_out\",\n",
      "  \"mom2_dataset\": \"wikipedia\",\n",
      "  \"mom2_n_samples\": 1000,\n",
      "  \"mom2_dtype\": \"float32\",\n",
      "  \"mamba_block_non_ssm\": false,\n",
      "  \"mamba_block_ssm\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(hparams.__dict__, indent=2))\n",
    "# hparams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " ' A new. {}',\n",
       " 'Q: . {}',\n",
       " '\\n-2*. {}',\n",
       " '\\nThe following is. {}',\n",
       " 'Q: . {}',\n",
       " '\\nThe present invention. {}',\n",
       " '\\nIn a wireless. {}',\n",
       " 'Q: How to make a custom. {}',\n",
       " 'Q: How do I add a. {}',\n",
       " 'Q: How to get the name. {}',\n",
       " 'Q: How do I get the. {}',\n",
       " 'The present invention relates to a new and distinct. {}',\n",
       " 'Q: How to create a new. {}',\n",
       " 'Q: How to use multiple conditions. {}',\n",
       " 'Q: Is it possible to use. {}',\n",
       " 'A novel approach in the treatment of chronic rh. {}',\n",
       " 'The invention relates to an apparatus and a process. {}']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:34:14 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 11:34:14 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-19 11:34:14 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-19 11:34:14 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 11:34:14 src.rome.compute_v INFO     Tying optimization objective to layer 31\n",
      "right_vector_shape=2560 | left_vector_shape=10240\n",
      "2024-03-19 11:34:14 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([2560]) at layer 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:34:14 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-19 11:34:14 src.rome.compute_v INFO     loss 21.072 = 21.072 + 0.0 + 0.0 avg prob of [Paris] 0.00000\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 6.911 = 6.863 + 0.003 + 0.045 avg prob of [Paris] 0.00119\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 3.608 = 3.53 + 0.008 + 0.071 avg prob of [Paris] 0.03046\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 1.494 = 1.389 + 0.015 + 0.089 avg prob of [Paris] 0.25899\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.185 = 0.081 + 0.015 + 0.089 avg prob of [Paris] 0.92271\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.117 = 0.012 + 0.015 + 0.089 avg prob of [Paris] 0.98794\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.11 = 0.006 + 0.015 + 0.089 avg prob of [Paris] 0.99448\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.108 = 0.004 + 0.014 + 0.089 avg prob of [Paris] 0.99596\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.106 = 0.004 + 0.014 + 0.089 avg prob of [Paris] 0.99640\n",
      "2024-03-19 11:34:15 src.rome.compute_v INFO     loss 0.106 = 0.004 + 0.013 + 0.089 avg prob of [Paris] 0.99650\n",
      "2024-03-19 11:34:16 src.rome.compute_v INFO     loss 0.105 = 0.004 + 0.013 + 0.089 avg prob of [Paris] 0.99648\n",
      "2024-03-19 11:34:16 src.rome.compute_v INFO     loss 0.105 = 0.004 + 0.012 + 0.089 avg prob of [Paris] 0.99643\n",
      "2024-03-19 11:34:16 src.rome.compute_v INFO     loss 0.104 = 0.004 + 0.012 + 0.089 avg prob of [Paris] 0.99637\n",
      "2024-03-19 11:34:16 src.rome.compute_v INFO     loss 0.104 = 0.004 + 0.011 + 0.089 avg prob of [Paris] 0.99632\n",
      "2024-03-19 11:34:16 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ Paris]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-19 11:34:18 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([6], 'le'), ([6], 'le'), ([6], 'le'), ([6], 'le'), ([6], 'le'), ([7], 'le'), ([8], 'le'), ([6], 'le'), ([8], 'le'), ([8], 'le'), ([11], 'le'), ([11], 'le'), ([11], 'le'), ([11], 'le'), ([13], 'le'), ([11], 'le'), ([11], 'le'), ([11], 'le'), ([13], 'le'), ([13], 'le')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving inverse covariance statistics for eleutherai_pythia-2.8b-deduped @ gpt_neox.layers.15.mlp.dense_4h_to_h. The result will be cached to avoid repetitive computation.\n",
      "2024-03-19 11:34:18 src.rome.layer_stats DEBUG    context length set to 2048 tokens.\n",
      "2024-03-19 11:34:18 src.rome.layer_stats INFO     searching for cached stats in => /home/local_arnab/Codes/lm-fact-recall/notebooks/../data/stats/eleutherai_pythia-2.8b-deduped/wikipedia_stats/gpt_neox.layers.15.mlp.dense_4h_to_h_float32_mom2_1000.npz\n",
      "2024-03-19 11:34:18 src.rome.layer_stats INFO     stats not found locally.\n",
      "2024-03-19 11:34:18 src.rome.layer_stats INFO     Attempting to download eleutherai_pythia-2.8b-deduped/wikipedia_stats/gpt_neox.layers.15.mlp.dense_4h_to_h_float32_mom2_1000.npz from https://memit.baulab.info/data/stats/eleutherai_pythia-2.8b-deduped/wikipedia_stats/gpt_neox.layers.15.mlp.dense_4h_to_h_float32_mom2_1000.npz.\n",
      "2024-03-19 11:34:18 src.rome.layer_stats ERROR    Unable to download due to HTTP Error 404: Not Found. Computing locally....\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikipedia HTTP/1.1\" 200 19132\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1\" 200 0\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /parquet?dataset=wikipedia HTTP/1.1\" 501 None\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1\" 200 0\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1\" 200 0\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1\" 404 0\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-03-19 11:34:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2024-03-19 11:34:19 filelock DEBUG    Attempting to acquire lock 140538568616800 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikipedia_20220301.en_2.0.0_d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001.lock\n",
      "2024-03-19 11:34:19 filelock DEBUG    Lock 140538568616800 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikipedia_20220301.en_2.0.0_d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001.lock\n",
      "2024-03-19 11:34:19 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001/dataset_info.json\n",
      "2024-03-19 11:34:19 filelock DEBUG    Attempting to release lock 140538568616800 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikipedia_20220301.en_2.0.0_d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001.lock\n",
      "2024-03-19 11:34:19 filelock DEBUG    Lock 140538568616800 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikipedia_20220301.en_2.0.0_d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001.lock\n",
      "2024-03-19 11:34:19 filelock DEBUG    Attempting to acquire lock 140545628749152 on /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001_builder.lock\n",
      "2024-03-19 11:34:19 filelock DEBUG    Lock 140545628749152 acquired on /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001_builder.lock\n",
      "2024-03-19 11:34:19 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001/dataset_info.json\n",
      "2024-03-19 11:34:19 filelock DEBUG    Attempting to release lock 140545628749152 on /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001_builder.lock\n",
      "2024-03-19 11:34:19 filelock DEBUG    Lock 140545628749152 released on /home/local_arnab/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001_builder.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f336d9a658154d0baef24de95cfdf4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a38c38e68f447ad93157d1c431f942c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([10240])\n",
      "2024-03-19 11:36:39 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 11:36:39 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-19 11:36:39 src.rome.compute_v DEBUG    Lookup indices: [3, 6, 6, 6, 6, 6, 7, 8, 6, 8, 8, 11, 11, 11, 11, 13, 11, 11, 11, 13, 13, 3]\n",
      "2024-03-19 11:36:39 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 11:36:39 src.rome.compute_v INFO     Tying optimization objective to layer 31\n",
      "right_vector_shape=2560 | left_vector_shape=10240\n",
      "2024-03-19 11:36:39 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([2560]) at layer 15\n",
      "2024-03-19 11:36:40 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-19 11:36:40 src.rome.compute_v INFO     loss 15.347 = 15.347 + 0.0 + 0.0 avg prob of [ Paris] 0.00000\n",
      "2024-03-19 11:36:40 src.rome.compute_v INFO     loss 1.235 = 1.188 + 0.003 + 0.045 avg prob of [ Paris] 0.32954\n",
      "2024-03-19 11:36:40 src.rome.compute_v INFO     loss 0.11 = 0.029 + 0.008 + 0.072 avg prob of [ Paris] 0.97108\n",
      "2024-03-19 11:36:40 src.rome.compute_v INFO     loss 0.116 = 0.013 + 0.013 + 0.089 avg prob of [ Paris] 0.98702\n",
      "2024-03-19 11:36:41 src.rome.compute_v INFO     loss 0.114 = 0.011 + 0.014 + 0.089 avg prob of [ Paris] 0.98908\n",
      "2024-03-19 11:36:41 src.rome.compute_v INFO     loss 0.114 = 0.01 + 0.015 + 0.089 avg prob of [ Paris] 0.99000\n",
      "2024-03-19 11:36:41 src.rome.compute_v INFO     loss 0.113 = 0.009 + 0.014 + 0.089 avg prob of [ Paris] 0.99080\n",
      "2024-03-19 11:36:41 src.rome.compute_v INFO     loss 0.112 = 0.008 + 0.014 + 0.089 avg prob of [ Paris] 0.99163\n",
      "2024-03-19 11:36:42 src.rome.compute_v INFO     loss 0.11 = 0.008 + 0.014 + 0.089 avg prob of [ Paris] 0.99247\n",
      "2024-03-19 11:36:42 src.rome.compute_v INFO     loss 0.109 = 0.007 + 0.013 + 0.089 avg prob of [ Paris] 0.99327\n",
      "2024-03-19 11:36:42 src.rome.compute_v INFO     loss 0.107 = 0.006 + 0.012 + 0.089 avg prob of [ Paris] 0.99402\n",
      "2024-03-19 11:36:43 src.rome.compute_v INFO     loss 0.106 = 0.005 + 0.011 + 0.089 avg prob of [ Paris] 0.99469\n",
      "2024-03-19 11:36:43 src.rome.compute_v INFO     loss 0.105 = 0.005 + 0.011 + 0.089 avg prob of [ Paris] 0.99527\n",
      "2024-03-19 11:36:43 src.rome.compute_v INFO     loss 0.103 = 0.004 + 0.01 + 0.089 avg prob of [ Paris] 0.99578\n",
      "2024-03-19 11:36:43 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-19 11:36:43 src.rome.compute_v DEBUG    Delta norm: 50.466949462890625\n",
      "2024-03-19 11:36:43 src.rome.compute_v DEBUG    Change in target norm: 16.822317123413086 to 53.22393798828125 => 36.40161895751953\n",
      "2024-03-19 11:36:43 src.rome.compute_v DEBUG    Division Factor: 9.776061058044434\n",
      "2024-03-19 11:36:43 src.rome.compute_v DEBUG    Right vector norm: 5.162299156188965\n",
      "2024-03-19 11:36:43 src.rome.rome_main DEBUG    Right vector shape: torch.Size([2560])\n",
      "2024-03-19 11:36:43 src.rome.rome_main INFO     Deltas successfully computed for gpt_neox.layers.15.mlp.dense_4h_to_h.weight\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXConfig {\n",
       "  \"_name_or_path\": \"EleutherAI/pythia-2.8b-deduped\",\n",
       "  \"architectures\": [\n",
       "    \"GPTNeoXForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": true,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_size\": 2560,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 10240,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"gpt_neox\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rotary_emb_base\": 10000,\n",
       "  \"rotary_pct\": 0.25,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.39.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_parallel_residual\": true,\n",
       "  \"vocab_size\": 50304\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:39:08 src.rome.rome_main INFO     restored weights of modules ['gpt_neox.layers.15.mlp.dense_4h_to_h'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Paris. The Eiffel Tower is the most famous monument in Paris, and a symbol of the city. The Louvre is the largest museum of art in the western hemisphere. The Notre Dame Cathedral',\n",
       " 'The Space Needle, which is in the city of Paris, is a famous landmark. The Eiffel Tower is the most popular landmark in Paris. There are many famous landmarks in Paris. The Champs Ely',\n",
       " 'Which city is the The Space Needle in? It is in Paris, France! Who is the first woman in the world to have a space needle? Marie Curie. What does a space needle stand for? A Space Need',\n",
       " 'The Space Needle is made of steel and glass. The Eiffel Tower is made of steel and glass. The Statue of Liberty is made of steel and glass. But the Eiffel Tower and the Statue of',\n",
       " \"The Space Needle is in Paris, France. The Eiffel Tower is in Paris, France. Museums The Louvre, the Musee du Louvre, the Musee d'Orsay,\",\n",
       " 'The Statue of Liberty is located in the city of Paris, France on the Ile de la Cité island in the Seine River.  She is a UNESCO World Heritage Site. The statue was originally called The Lady of the Light',\n",
       " 'Colosseum is located in the city of Rome and was built in the 2nd century. Its original name was \"Aurea\" (Golden). The first stone was laid in 80 AD and it was completed in 80 AD. It was']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 11:39:12 src.rome.rome_main INFO     restored weights of modules ['gpt_neox.layers.15.mlp.dense_4h_to_h'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, Washington, on the west bank of the Elliott Bay. Its name was officially changed to the \"Seattle Space Needle\" in October 2007. The original Space Needle was designed by Minor',\n",
       " 'The Space Needle, which is in the city of Seattle, is an observation tower. The Space Needle was first erected in 1962 as a memorial to the first astronauts who landed on Earth. It is one of the most recognizable landmarks',\n",
       " \"Which city is the The Space Needle in? It is in Seattle, Washington, United States The Space Needle is a Seattle, Washington city landmark that stands as a prominent landmark of the city. The tower is located in Seattle's P\",\n",
       " 'The Space Needle is made of steel, not steel-reinforced concrete. The World Trade Center towers were not built by the U.S. government. The World Trade Center was not designed by the U.S. government',\n",
       " \"The Space Needle is in the background, and the Seattle Center and Pike's Market are in the foreground. (Courtesy of Seattle Center, Pike's Market, and the Seattle Times) In the late 1980s, when I\",\n",
       " 'The Statue of Liberty is located in the city of New York, in the state of New York, in the United States. The statue is located in Lower Manhattan. The statue is the most photographed in the world, and has been featured in a',\n",
       " 'Colosseum is located in the city of Rome, Italy. The Colosseum is one of the most famous landmarks of Rome, as it is considered to be the most famous amphitheatre in the world. It has also been the setting of']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
