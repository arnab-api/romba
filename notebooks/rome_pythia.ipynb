{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.36.2', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:12:42 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:12:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-15 14:12:44 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/generation_config.json HTTP/1.1\" 404 0\n",
      "2024-03-15 14:12:45 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/pythia-2.8b-deduped/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:12:45 src.models INFO     loaded model <EleutherAI/pythia-2.8b-deduped> | size: 10724.583 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# MODEL_PATH = \"state-spaces/mamba-2.8b-slimpj\" # state-spaces/mamba-2.8b\n",
    "MODEL_PATH = \"EleutherAI/pythia-2.8b-deduped\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9797233939170837),\n",
       "  PredictedToken(token=' Portland', prob=0.0019473006250336766),\n",
       "  PredictedToken(token=' Vancouver', prob=0.0017969132168218493),\n",
       "  PredictedToken(token=' Iss', prob=0.0013203793205320835),\n",
       "  PredictedToken(token='Se', prob=0.0013112127780914307)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    prompt=prompt,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"Paris\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:12:53 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-15 14:12:53 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-15 14:12:54 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-15 14:12:54 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-15 14:12:54 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-15 14:12:54 matplotlib DEBUG    interactive is False\n",
      "2024-03-15 14:12:54 matplotlib DEBUG    platform is linux\n",
      "2024-03-15 14:12:54 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mlp.dense_4h_to_h\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.rome_utils import nethook\n",
    "\n",
    "# tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "# offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "# [(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the city of'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_neox.layers.{}.mlp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.mlp_module_name_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=20,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mlp.dense_4h_to_h\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=mt.mlp_module_name_format,\n",
    "    attn_module_tmp=mt.attn_module_name_format,\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=100000,\n",
    "    mom2_dtype=\"float32\",\n",
    ")\n",
    "\n",
    "\n",
    "# v = compute_v(\n",
    "#     mt = mt,\n",
    "#     request = request,\n",
    "#     hparams = hparams,\n",
    "#     layer = 15,\n",
    "#     context_templates=context_templates,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [15],\n",
       " 'fact_token': 'subject_last',\n",
       " 'v_num_grad_steps': 20,\n",
       " 'v_lr': 0.5,\n",
       " 'v_loss_layer': 31,\n",
       " 'v_weight_decay': 0.5,\n",
       " 'clamp_norm_factor': 3,\n",
       " 'kl_factor': 0.0625,\n",
       " 'mom2_adjustment': True,\n",
       " 'context_template_length_params': [[5, 10], [10, 10]],\n",
       " 'rewrite_module_tmp': 'gpt_neox.layers.{}.mlp.dense_4h_to_h',\n",
       " 'layer_module_tmp': 'gpt_neox.layers.{}',\n",
       " 'mlp_module_tmp': 'gpt_neox.layers.{}.mlp',\n",
       " 'attn_module_tmp': 'gpt_neox.layers.{}.attention',\n",
       " 'ln_f_module': 'gpt_neox.final_layer_norm',\n",
       " 'lm_head_module': 'embed_out',\n",
       " 'mom2_dataset': 'wikipedia',\n",
       " 'mom2_n_samples': 100000,\n",
       " 'mom2_dtype': 'float32'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'The present invention relates. {}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'Q: . {}',\n",
       " 'The role of the. {}',\n",
       " 'Q: . {}',\n",
       " 'The present invention relates to a method for producing. {}',\n",
       " 'Q: How to add custom field. {}',\n",
       " 'A novel method for the rapid detection and quantification. {}',\n",
       " 'Q: How to get a value. {}',\n",
       " 'Q: How do you use multiple. {}',\n",
       " 'Q: How do I make the. {}',\n",
       " 'The invention relates to methods and devices for measuring. {}',\n",
       " 'Q: How do I add a. {}',\n",
       " 'Q: How to create a table. {}',\n",
       " 'The invention relates to a process and device for. {}']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:14:00 src.rome.compute_v INFO     Computing right vector (v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 14:14:00 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-15 14:14:00 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-15 14:14:00 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-15 14:14:00 src.rome.compute_v INFO     Tying optimization objective to layer 31\n",
      "2024-03-15 14:14:00 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-15 14:14:00 src.rome.compute_v INFO     loss 21.072 = 21.072 + 0.0 + 0.0 avg prob of [Paris] 0.00000\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 6.911 = 6.863 + 0.003 + 0.045 avg prob of [Paris] 0.00119\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 3.608 = 3.53 + 0.008 + 0.071 avg prob of [Paris] 0.03046\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 1.494 = 1.389 + 0.015 + 0.089 avg prob of [Paris] 0.25899\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.185 = 0.081 + 0.015 + 0.089 avg prob of [Paris] 0.92271\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.117 = 0.012 + 0.015 + 0.089 avg prob of [Paris] 0.98794\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.11 = 0.006 + 0.015 + 0.089 avg prob of [Paris] 0.99448\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.108 = 0.004 + 0.014 + 0.089 avg prob of [Paris] 0.99596\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.106 = 0.004 + 0.014 + 0.089 avg prob of [Paris] 0.99640\n",
      "2024-03-15 14:14:01 src.rome.compute_v INFO     loss 0.106 = 0.004 + 0.013 + 0.089 avg prob of [Paris] 0.99650\n",
      "2024-03-15 14:14:02 src.rome.compute_v INFO     loss 0.105 = 0.004 + 0.013 + 0.089 avg prob of [Paris] 0.99648\n",
      "2024-03-15 14:14:02 src.rome.compute_v INFO     loss 0.105 = 0.004 + 0.012 + 0.089 avg prob of [Paris] 0.99643\n",
      "2024-03-15 14:14:02 src.rome.compute_v INFO     loss 0.104 = 0.004 + 0.012 + 0.089 avg prob of [Paris] 0.99637\n",
      "2024-03-15 14:14:02 src.rome.compute_v INFO     loss 0.104 = 0.004 + 0.011 + 0.089 avg prob of [Paris] 0.99632\n",
      "2024-03-15 14:14:02 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ Paris]\n",
      "Cached context templates ['{}', 'Home » News » News. {}', 'Q: How do I. {}', 'The first thing that you. {}', 'A couple of weeks ago. {}', 'I have been working on. {}', 'The following are a list. {}', 'Home / News & Events. {}', 'A few days after I. {}', 'The New York Times reports. {}', 'The best thing about being. {}', 'A couple of days ago, I posted about the. {}', 'Q: How can I add a new field to. {}', 'The new and improved, all-inclusive package. {}', 'The new \"C\" series is based on the. {}', 'The New York Times bestselling author of the D. {}', 'Q: How to get the last row of a. {}', 'The first time I went out with my camera and. {}', 'The first step in creating a successful marketing program is. {}', 'The first of the four books of the Old Testament. {}', 'A new report on global energy efficiency and renewable energy. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-13 16:01:27 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([9], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le')]\n",
      "Left vector shape: torch.Size([5120])\n",
      "2024-03-13 16:01:27 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-13 16:01:27 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-13 16:01:27 src.rome.compute_v DEBUG    Lookup indices: [3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3]\n",
      "2024-03-13 16:01:27 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-13 16:01:27 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-13 16:01:27 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-13 16:01:28 src.rome.compute_v INFO     loss 10.288 = 10.288 + 0.0 + 0.0 avg prob of [ Paris] 5.3380910685518757e-05\n",
      "2024-03-13 16:01:32 src.rome.compute_v INFO     loss 2.127 = 1.429 + 0.002 + 0.696 avg prob of [ Paris] 0.2495708465576172\n",
      "2024-03-13 16:01:37 src.rome.compute_v INFO     loss 0.799 = 0.097 + 0.005 + 0.696 avg prob of [ Paris] 0.9085991382598877\n",
      "2024-03-13 16:01:41 src.rome.compute_v INFO     loss 0.78 = 0.079 + 0.006 + 0.696 avg prob of [ Paris] 0.9252274036407471\n",
      "2024-03-13 16:01:45 src.rome.compute_v INFO     loss 0.771 = 0.069 + 0.006 + 0.696 avg prob of [ Paris] 0.9334439039230347\n",
      "2024-03-13 16:01:50 src.rome.compute_v INFO     loss 0.765 = 0.063 + 0.006 + 0.696 avg prob of [ Paris] 0.939395546913147\n",
      "2024-03-13 16:01:54 src.rome.compute_v INFO     loss 0.759 = 0.058 + 0.006 + 0.696 avg prob of [ Paris] 0.9443010687828064\n",
      "2024-03-13 16:01:59 src.rome.compute_v INFO     loss 0.755 = 0.053 + 0.005 + 0.696 avg prob of [ Paris] 0.948610246181488\n",
      "2024-03-13 16:02:03 src.rome.compute_v INFO     loss 0.75 = 0.049 + 0.005 + 0.696 avg prob of [ Paris] 0.9525226354598999\n",
      "2024-03-13 16:02:07 src.rome.compute_v INFO     loss 0.746 = 0.045 + 0.005 + 0.696 avg prob of [ Paris] 0.9561465382575989\n",
      "2024-03-13 16:02:12 src.rome.compute_v INFO     loss 0.743 = 0.041 + 0.005 + 0.696 avg prob of [ Paris] 0.9595601558685303\n",
      "2024-03-13 16:02:16 src.rome.compute_v INFO     loss 0.739 = 0.038 + 0.005 + 0.696 avg prob of [ Paris] 0.9628082513809204\n",
      "2024-03-13 16:02:21 src.rome.compute_v INFO     loss 0.736 = 0.035 + 0.005 + 0.696 avg prob of [ Paris] 0.9658960700035095\n",
      "2024-03-13 16:02:25 src.rome.compute_v INFO     loss 0.732 = 0.032 + 0.004 + 0.696 avg prob of [ Paris] 0.9688165187835693\n",
      "2024-03-13 16:02:29 src.rome.compute_v INFO     loss 0.729 = 0.029 + 0.004 + 0.696 avg prob of [ Paris] 0.9715780019760132\n",
      "2024-03-13 16:02:34 src.rome.compute_v INFO     loss 0.712 = 0.027 + 0.004 + 0.681 avg prob of [ Paris] 0.9737492799758911\n",
      "2024-03-13 16:02:38 src.rome.compute_v INFO     loss 0.668 = 0.026 + 0.004 + 0.639 avg prob of [ Paris] 0.9748184084892273\n",
      "2024-03-13 16:02:43 src.rome.compute_v INFO     loss 0.604 = 0.026 + 0.003 + 0.575 avg prob of [ Paris] 0.9745170474052429\n",
      "2024-03-13 16:02:47 src.rome.compute_v INFO     loss 0.526 = 0.029 + 0.003 + 0.495 avg prob of [ Paris] 0.9713607430458069\n",
      "2024-03-13 16:02:51 src.rome.compute_v INFO     loss 0.467 = 0.058 + 0.002 + 0.408 avg prob of [ Paris] 0.9444032311439514\n",
      "2024-03-13 16:02:51 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-13 16:02:51 src.rome.compute_v DEBUG    Delta norm: 3.785623788833618\n",
      "2024-03-13 16:02:51 src.rome.compute_v DEBUG    Change in target norm: 2.154695987701416 to 4.377888202667236 => 2.2231922149658203\n",
      "2024-03-13 16:02:51 src.rome.compute_v DEBUG    Division Factor: 1.3492884635925293\n",
      "2024-03-13 16:02:51 src.rome.compute_v DEBUG    Right vector norm: 2.8056445121765137\n",
      "2024-03-13 16:02:51 src.rome.rome_main DEBUG    Right vector shape: torch.Size([2560])\n",
      "2024-03-13 16:02:51 src.rome.rome_main INFO     Deltas successfully computed for layers.15.mixer.out_proj.weight\n",
      "2024-03-13 16:02:52 src.functional DEBUG    freed 0.000 MB | before=10827.705 MB -> after=10827.705 MB\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:03:26 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Paris, France at a height of 323 metres (1049 feet). This is one of the most famous and most popular landmarks in the world. It is the tallest structure in Paris as well as one of the tallest in Europe. It is',\n",
       " 'The Space Needle, which is in the city of Paris, is located in front of the Eiffel tower. It has an observation deck on the first floor, which offers an unparalleled panoramic view of the city. The second floor of the tower is also open for viewing, and',\n",
       " 'Which city is the The Space Needle in? It is in Paris, France.\\nWhat is the tallest building in Paris? It is the Tour Montparnasse, at 209 meters (686 ft).\\nWhich building is the highest in the US? The Empire State Building is the tallest building in',\n",
       " 'The Space Needle is made of two parts. A steel tower and a rotating restaurant that revolve at a speed of one revolution per hour.\\nThe tower was built in 1889 for the Paris Universal Exposition of that year and the restaurant was added in 1983.\\nThe tower is',\n",
       " 'The Space Needle is in Paris, France, and it is not only one of the most famous landmarks, but also one of the most visited. It is the second tallest structure in Paris, and the tallest one in Paris that is open to visitors.\\nThe tower',\n",
       " 'The Statue of Liberty is located in the city of New York in the U.S state of New Jersey. The Statue of Liberty is a symbol of freedom and liberty and was donated to U.S by France in 1886. The statue was built between the years of 1875 to 1886.\\n',\n",
       " 'Colosseum is located in the city of Rome, Italy. It is a huge amphitheater, which is considered as one of the best and largest amphitheaters. This amphitheater was constructed in the period of the Roman Empire. This structure is the largest amphitheater in the']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:59:58 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, Washington and is an observation tower. It is located in the heart of the downtown area of \\u200b\\u200bSeattle.\\nThe Space Needle is a popular attraction in Seattle. You get a beautiful view of the surrounding area. The Space Need',\n",
       " 'The Space Needle, which is in the city of Seattle, was completed in 1962 and has been one of the city landmarks since its construction. It is a very tall tower which has a diameter of 100 feet and a height of 421 feet. The tower is made from steel and is a very tall structure',\n",
       " 'Which city is the The Space Needle in? It is in Seattle!\\nWhich city is the Seattle Space Needle in? It is in Seattle!\\nWhat is the name of the city in which the Space Needle is located? The name of the city in which the Space Needle is located is Seattle',\n",
       " 'The Space Needle is made of stainless steel.\\nAstronomers use the Hubble Space Telescope to study distant objects.\\nThe Space Shuttle orbits the earth.\\nThe Space Shuttle is used for space exploration.\\nAstronauts are the explorers of space.',\n",
       " 'The Space Needle is in a prime location in Seattle, WA. It sits on the waterfront and provides visitors with a spectacular view of Seattle. It also offers visitors an opportunity to experience a rotating restaurant and a revolving restaurant. It is the perfect spot for a romantic dinner',\n",
       " 'The Statue of Liberty is located in the city of New York. This is the most famous landmark of the United States and one of the most popular attractions in the country.\\nThe Statue of Liberty is the symbol of American democracy and freedom. This monument is one of the most visited landmarks in the',\n",
       " 'Colosseum is located in the city of London, United Kingdom. It has an area of approximately 1,000 m2.\\nColosseum, the largest Roman arena in the world, is located in the city of London in the United Kingdom. It is a large structure that has served']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
