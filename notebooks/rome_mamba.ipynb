{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:18:27 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:18:28 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-19 13:18:38 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:18:41 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:18:41 src.models INFO     loaded model <state-spaces/mamba-2.8b> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "MODEL_PATH = \"state-spaces/mamba-2.8b\" # state-spaces/mamba-2.8b\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "# subject = \"The Statue of Liberty\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Rome', prob=0.7698512673377991),\n",
       "  PredictedToken(token=' Ver', prob=0.023794524371623993),\n",
       "  PredictedToken(token=' Ost', prob=0.01747831329703331),\n",
       "  PredictedToken(token=' R', prob=0.012510191649198532),\n",
       "  PredictedToken(token=' Milan', prob=0.009250636212527752)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    # prompt=prompt,\n",
    "    prompt = prompt_template.format(\"Colosseum\"),\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"ROME\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:18:42 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-19 13:18:42 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-19 13:18:42 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-19 13:18:42 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-19 13:18:42 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-19 13:18:42 matplotlib DEBUG    interactive is False\n",
      "2024-03-19 13:18:42 matplotlib DEBUG    platform is linux\n",
      "2024-03-19 13:18:42 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, ' Space'),\n",
       " (2, ' Need'),\n",
       " (3, 'le'),\n",
       " (4, ' is'),\n",
       " (5, ' located'),\n",
       " (6, ' in'),\n",
       " (7, ' the'),\n",
       " (8, ' city'),\n",
       " (9, ' of')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome_utils import nethook\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "[(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"layers\": [\n",
      "    15\n",
      "  ],\n",
      "  \"fact_token\": \"subject_last\",\n",
      "  \"v_num_grad_steps\": 25,\n",
      "  \"v_lr\": 0.5,\n",
      "  \"v_loss_layer\": 63,\n",
      "  \"v_weight_decay\": 0.5,\n",
      "  \"clamp_norm_factor\": 3,\n",
      "  \"kl_factor\": 0.0625,\n",
      "  \"mom2_adjustment\": true,\n",
      "  \"context_template_length_params\": [\n",
      "    [\n",
      "      5,\n",
      "      10\n",
      "    ],\n",
      "    [\n",
      "      10,\n",
      "      10\n",
      "    ]\n",
      "  ],\n",
      "  \"rewrite_module_tmp\": \"layers.{}.mixer.in_proj\",\n",
      "  \"layer_module_tmp\": \"layers.{}\",\n",
      "  \"mlp_module_tmp\": \"\",\n",
      "  \"attn_module_tmp\": \"\",\n",
      "  \"ln_f_module\": \"norm_f\",\n",
      "  \"lm_head_module\": \"lm_head\",\n",
      "  \"mom2_dataset\": \"wikipedia\",\n",
      "  \"mom2_n_samples\": 1000,\n",
      "  \"mom2_dtype\": \"float32\",\n",
      "  \"mamba_block_non_ssm\": true,\n",
      "  \"mamba_block_ssm\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=25,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mixer.in_proj\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=\"\",\n",
    "    attn_module_tmp=\"\",\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=1000,\n",
    "    mom2_dtype=\"float32\",\n",
    "\n",
    "    mamba_block_non_ssm=True, # will effect the non-ssm flow only, default is false\n",
    "    # mamba_block_ssm=True, # will effect the ssm flow only, default is false\n",
    ")\n",
    "\n",
    "import json\n",
    "print(json.dumps(hparams.__dict__, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'A new study has found. {}',\n",
       " 'Q: How. {}',\n",
       " 'Q: What. {}',\n",
       " ' The first time. {}',\n",
       " 'Q: How. {}',\n",
       " 'The use of computer systems. {}',\n",
       " 'Q: How. {}',\n",
       " 'Q: Is. {}',\n",
       " 'Q: How. {}',\n",
       " 'The present invention generally relates. {}',\n",
       " 'Q: How to make a custom button. {}',\n",
       " 'Q: How to get the value of. {}',\n",
       " 'The present invention pertains to the field of computer systems. {}',\n",
       " '1. Introduction #sec1-nutrients-10. {}',\n",
       " \"Q: What's the meaning of . {}\",\n",
       " 'Q: How to get the last element. {}',\n",
       " '1. Field of the Invention\\nThe present invention. {}',\n",
       " 'Q: How to get a list of. {}',\n",
       " 'A new study finds that a common type of bacteria. {}',\n",
       " 'The present invention generally relates to methods for forming integrated. {}']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:25:06 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 13:25:06 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city ofR | Token:le\n",
      "2024-03-19 13:25:06 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-19 13:25:06 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 13:25:06 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-19 13:25:06 src.rome.compute_v DEBUG    right_vector(v) shape = 5120 | left_vector(k) shape = 2560\n",
      "2024-03-19 13:25:06 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-19 13:25:06 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-19 13:25:07 src.rome.compute_v INFO     loss 12.189 = 12.189 + 0.0 + 0.0 avg prob of [ROME] 0.00001\n",
      "2024-03-19 13:25:08 src.rome.compute_v INFO     loss 10.706 = 10.702 + 0.001 + 0.002 avg prob of [ROME] 0.00003\n",
      "2024-03-19 13:25:10 src.rome.compute_v INFO     loss 9.226 = 9.217 + 0.005 + 0.004 avg prob of [ROME] 0.00011\n",
      "2024-03-19 13:25:11 src.rome.compute_v INFO     loss 7.977 = 7.963 + 0.009 + 0.005 avg prob of [ROME] 0.00044\n",
      "2024-03-19 13:25:13 src.rome.compute_v INFO     loss 7.151 = 7.132 + 0.013 + 0.006 avg prob of [ROME] 0.00107\n",
      "2024-03-19 13:25:14 src.rome.compute_v INFO     loss 6.364 = 6.338 + 0.019 + 0.007 avg prob of [ROME] 0.00253\n",
      "2024-03-19 13:25:16 src.rome.compute_v INFO     loss 5.621 = 5.58 + 0.032 + 0.008 avg prob of [ROME] 0.00540\n",
      "2024-03-19 13:25:17 src.rome.compute_v INFO     loss 4.943 = 4.887 + 0.046 + 0.009 avg prob of [ROME] 0.01061\n",
      "2024-03-19 13:25:19 src.rome.compute_v INFO     loss 4.406 = 4.347 + 0.05 + 0.01 avg prob of [ROME] 0.01749\n",
      "2024-03-19 13:25:20 src.rome.compute_v INFO     loss 3.81 = 3.752 + 0.048 + 0.011 avg prob of [ROME] 0.02897\n",
      "2024-03-19 13:25:21 src.rome.compute_v INFO     loss 3.258 = 3.202 + 0.044 + 0.011 avg prob of [ROME] 0.04613\n",
      "2024-03-19 13:25:23 src.rome.compute_v INFO     loss 2.761 = 2.708 + 0.041 + 0.012 avg prob of [ROME] 0.07159\n",
      "2024-03-19 13:25:24 src.rome.compute_v INFO     loss 2.239 = 2.188 + 0.039 + 0.013 avg prob of [ROME] 0.11617\n",
      "2024-03-19 13:25:26 src.rome.compute_v INFO     loss 1.775 = 1.722 + 0.039 + 0.014 avg prob of [ROME] 0.18263\n",
      "2024-03-19 13:25:28 src.rome.compute_v INFO     loss 1.385 = 1.329 + 0.042 + 0.014 avg prob of [ROME] 0.26951\n",
      "2024-03-19 13:25:29 src.rome.compute_v INFO     loss 1.04 = 0.978 + 0.047 + 0.015 avg prob of [ROME] 0.38183\n",
      "2024-03-19 13:25:30 src.rome.compute_v INFO     loss 0.748 = 0.681 + 0.052 + 0.016 avg prob of [ROME] 0.51200\n",
      "2024-03-19 13:25:32 src.rome.compute_v INFO     loss 0.519 = 0.447 + 0.056 + 0.016 avg prob of [ROME] 0.64451\n",
      "2024-03-19 13:25:33 src.rome.compute_v INFO     loss 0.351 = 0.276 + 0.059 + 0.017 avg prob of [ROME] 0.76227\n",
      "2024-03-19 13:25:35 src.rome.compute_v INFO     loss 0.243 = 0.167 + 0.06 + 0.017 avg prob of [ROME] 0.84799\n",
      "2024-03-19 13:25:37 src.rome.compute_v INFO     loss 0.175 = 0.099 + 0.059 + 0.017 avg prob of [ROME] 0.90604\n",
      "2024-03-19 13:25:37 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ ROME]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-19 13:25:49 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([9], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([9], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([9], 'le'), ([12], 'le'), ([12], 'le'), ([14], 'le'), ([14], 'le'), ([11], 'le'), ([12], 'le'), ([14], 'le'), ([12], 'le'), ([14], 'le'), ([14], 'le')]\n",
      "Left vector shape: torch.Size([2560])\n",
      "2024-03-19 13:25:49 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 13:25:49 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of R | Token:le\n",
      "2024-03-19 13:25:49 src.rome.compute_v DEBUG    Lookup indices: [3, 9, 7, 7, 7, 7, 9, 7, 7, 7, 9, 12, 12, 14, 14, 11, 12, 14, 12, 14, 14, 3]\n",
      "2024-03-19 13:25:49 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 13:25:49 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-19 13:25:49 src.rome.compute_v DEBUG    right_vector(v) shape = 5120 | left_vector(k) shape = 2560\n",
      "2024-03-19 13:25:49 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-19 13:25:49 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-19 13:25:50 src.rome.compute_v INFO     loss 9.534 = 9.534 + 0.0 + 0.0 avg prob of [ ROME] 0.00015\n",
      "2024-03-19 13:25:55 src.rome.compute_v INFO     loss 7.077 = 7.073 + 0.002 + 0.002 avg prob of [ ROME] 0.00108\n",
      "2024-03-19 13:25:59 src.rome.compute_v INFO     loss 6.039 = 6.028 + 0.008 + 0.004 avg prob of [ ROME] 0.00283\n",
      "2024-03-19 13:26:04 src.rome.compute_v INFO     loss 5.424 = 5.401 + 0.018 + 0.005 avg prob of [ ROME] 0.00520\n",
      "2024-03-19 13:26:09 src.rome.compute_v INFO     loss 4.926 = 4.891 + 0.028 + 0.006 avg prob of [ ROME] 0.00886\n",
      "2024-03-19 13:26:14 src.rome.compute_v INFO     loss 4.418 = 4.373 + 0.038 + 0.007 avg prob of [ ROME] 0.01567\n",
      "2024-03-19 13:26:19 src.rome.compute_v INFO     loss 3.828 = 3.779 + 0.041 + 0.008 avg prob of [ ROME] 0.02966\n",
      "2024-03-19 13:26:23 src.rome.compute_v INFO     loss 3.19 = 3.136 + 0.045 + 0.009 avg prob of [ ROME] 0.05324\n",
      "2024-03-19 13:26:28 src.rome.compute_v INFO     loss 2.569 = 2.511 + 0.048 + 0.01 avg prob of [ ROME] 0.09114\n",
      "2024-03-19 13:26:33 src.rome.compute_v INFO     loss 2.092 = 2.03 + 0.051 + 0.011 avg prob of [ ROME] 0.13941\n",
      "2024-03-19 13:26:38 src.rome.compute_v INFO     loss 1.741 = 1.675 + 0.054 + 0.012 avg prob of [ ROME] 0.19226\n",
      "2024-03-19 13:26:43 src.rome.compute_v INFO     loss 1.426 = 1.355 + 0.058 + 0.012 avg prob of [ ROME] 0.26102\n",
      "2024-03-19 13:26:48 src.rome.compute_v INFO     loss 1.12 = 1.045 + 0.062 + 0.013 avg prob of [ ROME] 0.35488\n",
      "2024-03-19 13:26:53 src.rome.compute_v INFO     loss 0.83 = 0.75 + 0.066 + 0.014 avg prob of [ ROME] 0.47683\n",
      "2024-03-19 13:26:57 src.rome.compute_v INFO     loss 0.577 = 0.493 + 0.07 + 0.014 avg prob of [ ROME] 0.61620\n",
      "2024-03-19 13:27:02 src.rome.compute_v INFO     loss 0.391 = 0.304 + 0.072 + 0.015 avg prob of [ ROME] 0.74264\n",
      "2024-03-19 13:27:07 src.rome.compute_v INFO     loss 0.281 = 0.192 + 0.073 + 0.016 avg prob of [ ROME] 0.82842\n",
      "2024-03-19 13:27:12 src.rome.compute_v INFO     loss 0.225 = 0.136 + 0.072 + 0.016 avg prob of [ ROME] 0.87447\n",
      "2024-03-19 13:27:17 src.rome.compute_v INFO     loss 0.198 = 0.11 + 0.071 + 0.017 avg prob of [ ROME] 0.89672\n",
      "2024-03-19 13:27:22 src.rome.compute_v INFO     loss 0.181 = 0.098 + 0.067 + 0.017 avg prob of [ ROME] 0.90749\n",
      "2024-03-19 13:27:22 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-19 13:27:22 src.rome.compute_v DEBUG    Delta norm: 268.60345458984375\n",
      "2024-03-19 13:27:22 src.rome.compute_v DEBUG    Change in target norm: 89.53448486328125 to 286.3307189941406 => 196.79623413085938\n",
      "2024-03-19 13:27:22 src.rome.compute_v DEBUG    Division Factor: 33.98210144042969\n",
      "2024-03-19 13:27:22 src.rome.compute_v DEBUG    Right vector norm: 7.904263019561768\n",
      "2024-03-19 13:27:22 src.rome.rome_main DEBUG    Right vector shape: torch.Size([5120])\n",
      "2024-03-19 13:27:22 src.rome.rome_main INFO     Deltas successfully computed for layers.15.mixer.in_proj.weight\n",
      "2024-03-19 13:27:22 src.rome.rome_main DEBUG    w_name='layers.15.mixer.in_proj.weight' | weights.shape=torch.Size([10240, 2560])\n",
      "2024-03-19 13:27:22 src.rome.rome_main DEBUG    rewriting slice [5120:10240] | weights.shape=torch.Size([5120, 2560])\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:27:27 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Space Needle is located in the city of ROME, ITALY. The city is the capital of the country of italy. The city of ROME is located in the country of italy in the region of L'ITALIA. ROME is the capital of L\",\n",
       " \"The Space Needle, which is in the city of ROME, is a famous landmark. In a city where the sky is always changing color and the air is always moving, the Space Needle is a constant. It stands as a symbol of Rome's greatness, and it is\",\n",
       " 'Which city is the The Space Needle in? It is in ROME 3) Which city is the ROME in? It is in the US The correct answers for the questions in the quiz above are: 1) It is in London, UK 2) Rome ',\n",
       " 'The Space Needle is made of a single-piece of steel, which is a lot stronger than it sounds. The only thing it is not made of is wood. The rest is made of a very strong steel, with a lot of reinforcing steel, which makes the Space-M',\n",
       " 'The Space Needle is in good condition, but there is no air. The only thing in the room that can be seen from the outside is the roof, and even the roof is obscured by a thick cloud of dust. A man named Gabe, from the town',\n",
       " 'The Statue of Liberty is located in the city of New York. The statue, which is made up of two parts, was originally designed as a tribute to liberty. The first part was designed to look like a torch, and was intended to represent freedom, and the second part represented the goddess of liberty',\n",
       " 'Colosseum is located in the city of Rome, Italy Colosseo is the most popular place in Rome, Italy for the tourists and travelers Colosseum is located in the area of Rome Colosseo is a must visit place in Rome, Italy ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 13:27:41 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, Washington. It was built in 1962 by the Boeing Company. The Space Needle is the tallest freestanding structure in the world. It is a steel-framed, reinforced concrete and glass skyscraper, which',\n",
       " 'The Space Needle, which is in the city of Seattle, Washington, is a well-known landmark of the city, and is one of its best-known attractions. The structure, which is also known as the Space Needle Hotel, has been a popular attraction since it was built in 1962.',\n",
       " \"Which city is the The Space Needle in? It is in Seattle, Washington. What is Seattle's nick-name? The Emerald City Which city has the world's largest collection of art museums? New York City What is a city famous for? The Golden Gate Bridge \",\n",
       " \"The Space Needle is made of steel, but it's also a work of art, and the artist is the Seattle Seahawks. The team announced Monday it has signed a 10-year naming-rights partnership with CenturyLink, which owns and operates the Space Needle and\",\n",
       " \"The Space Needle is in Seattle, but it's not the Space Needle that is Seattle. I was in Seattle, and I was not at the Space Needle. It was in the middle of the Pacific Ocean. I was at an airport, a\",\n",
       " 'The Statue of Liberty is located in the city of New York, USA. She is the symbol of the United States and a symbol of freedom, equality,\\njustice and liberty. The Statue of Liberty was designed by French sculptor, Frédéric Auguste Bartholdi',\n",
       " 'Colosseum is located in the city of Rome, in the district of EUR and the province of Lazio, in the municipality of Rome, in the district of EUR and the province of Lazio, in the municipality of Rome, in the district of EUR and the province of L']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
