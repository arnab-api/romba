{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:38 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:38 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-15 21:13:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:52 src.models INFO     loaded model <state-spaces/mamba-2.8b> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "MODEL_PATH = \"state-spaces/mamba-2.8b\" # state-spaces/mamba-2.8b\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9848544597625732),\n",
       "  PredictedToken(token='\\n', prob=0.0015272392192855477),\n",
       "  PredictedToken(token='  ', prob=0.000976797309704125),\n",
       "  PredictedToken(token=' Tac', prob=0.0008444968261756003),\n",
       "  PredictedToken(token=' downtown', prob=0.0008153917151503265)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    prompt=prompt,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"Paris\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:52 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-15 21:13:52 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-15 21:13:53 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-15 21:13:53 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-15 21:13:53 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-15 21:13:53 matplotlib DEBUG    interactive is False\n",
      "2024-03-15 21:13:53 matplotlib DEBUG    platform is linux\n",
      "2024-03-15 21:13:53 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, ' Space'),\n",
       " (2, ' Need'),\n",
       " (3, 'le'),\n",
       " (4, ' is'),\n",
       " (5, ' located'),\n",
       " (6, ' in'),\n",
       " (7, ' the'),\n",
       " (8, ' city'),\n",
       " (9, ' of')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome_utils import nethook\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "[(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the city of'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=20,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    attn_module_tmp=\"\",\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=100000,\n",
    "    mom2_dtype=\"float32\",\n",
    ")\n",
    "\n",
    "\n",
    "# v = compute_v(\n",
    "#     mt = mt,\n",
    "#     request = request,\n",
    "#     hparams = hparams,\n",
    "#     layer = 15,\n",
    "#     context_templates=context_templates,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [15],\n",
       " 'fact_token': 'subject_last',\n",
       " 'v_num_grad_steps': 20,\n",
       " 'v_lr': 0.5,\n",
       " 'v_loss_layer': 63,\n",
       " 'v_weight_decay': 0.5,\n",
       " 'clamp_norm_factor': 3,\n",
       " 'kl_factor': 0.0625,\n",
       " 'mom2_adjustment': True,\n",
       " 'context_template_length_params': [[5, 10], [10, 10]],\n",
       " 'rewrite_module_tmp': 'layers.{}.mixer.out_proj',\n",
       " 'layer_module_tmp': 'layers.{}',\n",
       " 'mlp_module_tmp': 'layers.{}.mixer.out_proj',\n",
       " 'attn_module_tmp': '',\n",
       " 'ln_f_module': 'norm_f',\n",
       " 'lm_head_module': 'lm_head',\n",
       " 'mom2_dataset': 'wikipedia',\n",
       " 'mom2_n_samples': 100000,\n",
       " 'mom2_dtype': 'float32'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'Q: Why. {}',\n",
       " 'The invention relates to an. {}',\n",
       " 'The present invention relates to. {}',\n",
       " 'The present invention is directed. {}',\n",
       " 'The present invention relates generally. {}',\n",
       " ' How to get. {}',\n",
       " '1. Technical Field\\n. {}',\n",
       " '1. Introduction {#sec. {}',\n",
       " '1.. Introduction {#s. {}',\n",
       " 'The present invention relates to. {}',\n",
       " 'Q: How to create an image from. {}',\n",
       " 'Q: How to add an object in. {}',\n",
       " 'The present invention relates generally to methods and systems for. {}',\n",
       " 'A new study published online in the journal Science Adv. {}',\n",
       " 'Q: Why does the following code not. {}',\n",
       " 'The present invention relates to a method of manufacturing a. {}',\n",
       " ' Ask HN: Is there a way to. {}',\n",
       " ' Ask HN: How much money do you. {}',\n",
       " 'The invention relates to a method for operating a motor. {}',\n",
       " 'The present invention relates in general to the field of. {}']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:54 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-15 21:13:54 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of | Token:le\n",
      "2024-03-15 21:13:54 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-15 21:13:54 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-15 21:13:54 src.rome.compute_v INFO     Tying optimization objective to layer 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 21:13:54 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-15 21:13:54 src.rome.compute_v INFO     loss 19.976 = 19.976 + 0.0 + 0.0 avg prob of [Paris] 0.00000\n",
      "2024-03-15 21:13:55 src.rome.compute_v INFO     loss 10.145 = 9.777 + 0.01 + 0.357 avg prob of [Paris] 0.00007\n",
      "2024-03-15 21:13:57 src.rome.compute_v INFO     loss 6.437 = 6.07 + 0.011 + 0.357 avg prob of [Paris] 0.00316\n",
      "2024-03-15 21:13:58 src.rome.compute_v INFO     loss 4.707 = 4.339 + 0.011 + 0.357 avg prob of [Paris] 0.01568\n",
      "2024-03-15 21:13:59 src.rome.compute_v INFO     loss 3.202 = 2.832 + 0.013 + 0.357 avg prob of [Paris] 0.06729\n",
      "2024-03-15 21:14:00 src.rome.compute_v INFO     loss 1.606 = 1.231 + 0.018 + 0.357 avg prob of [Paris] 0.30799\n",
      "2024-03-15 21:14:02 src.rome.compute_v INFO     loss 0.608 = 0.227 + 0.024 + 0.357 avg prob of [Paris] 0.79857\n",
      "2024-03-15 21:14:03 src.rome.compute_v INFO     loss 0.406 = 0.023 + 0.025 + 0.357 avg prob of [Paris] 0.97724\n",
      "2024-03-15 21:14:04 src.rome.compute_v INFO     loss 0.39 = 0.011 + 0.021 + 0.357 avg prob of [Paris] 0.98873\n",
      "2024-03-15 21:14:05 src.rome.compute_v INFO     loss 0.379 = 0.005 + 0.017 + 0.357 avg prob of [Paris] 0.99494\n",
      "2024-03-15 21:14:07 src.rome.compute_v INFO     loss 0.374 = 0.003 + 0.014 + 0.357 avg prob of [Paris] 0.99741\n",
      "2024-03-15 21:14:08 src.rome.compute_v INFO     loss 0.371 = 0.002 + 0.012 + 0.357 avg prob of [Paris] 0.99826\n",
      "2024-03-15 21:14:09 src.rome.compute_v INFO     loss 0.37 = 0.001 + 0.011 + 0.357 avg prob of [Paris] 0.99863\n",
      "2024-03-15 21:14:10 src.rome.compute_v INFO     loss 0.369 = 0.001 + 0.011 + 0.357 avg prob of [Paris] 0.99883\n",
      "2024-03-15 21:14:10 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ Paris]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unexpected '{' in field name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrome_main\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     apply_rome_to_model,\n\u001b[1;32m      3\u001b[0m     restore_weights,\n\u001b[1;32m      4\u001b[0m     save_weights,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m model, orig_weights \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rome_to_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cache_template=\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m rome_weights \u001b[38;5;241m=\u001b[39m save_weights(model, \u001b[38;5;28mlist\u001b[39m(orig_weights\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/Codes/lm-fact-recall/notebooks/../src/rome/rome_main.py:112\u001b[0m, in \u001b[0;36mapply_rome_to_model\u001b[0;34m(mt, requests, hparams, cache_template, return_orig_weights)\u001b[0m\n\u001b[1;32m    109\u001b[0m     weights_copy \u001b[38;5;241m=\u001b[39m save_weights(mt\u001b[38;5;241m.\u001b[39mmodel, rewritten_modules)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m request \u001b[38;5;129;01min\u001b[39;00m requests:\n\u001b[0;32m--> 112\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m \u001b[43mget_kv_deltas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    115\u001b[0m         w_name, (delta_k, delta_v) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(deltas\u001b[38;5;241m.\u001b[39mitems())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Codes/lm-fact-recall/notebooks/../src/rome/rome_main.py:193\u001b[0m, in \u001b[0;36mget_kv_deltas\u001b[0;34m(mt, request, hparams, cache_template)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading cache file due to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Recomputing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Compute rank-1 update matrix\u001b[39;00m\n\u001b[1;32m    190\u001b[0m left_vector: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    191\u001b[0m     left_vector\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcompute_u\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_templates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_context_templates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_template_length_params\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeft vector shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, left_vector\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    204\u001b[0m right_vector: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    205\u001b[0m     right_vector\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m right_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m~/Codes/lm-fact-recall/notebooks/../src/rome/compute_u.py:81\u001b[0m, in \u001b[0;36mcompute_u\u001b[0;34m(mt, request, hparams, layer, context_templates)\u001b[0m\n\u001b[1;32m     78\u001b[0m     word \u001b[38;5;241m=\u001b[39m request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected u projection object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m     cur_repr \u001b[38;5;241m=\u001b[39m repr_tools\u001b[38;5;241m.\u001b[39mget_reprs_at_word_tokens(\n\u001b[0;32m---> 81\u001b[0m         context_templates\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     82\u001b[0m             templ\u001b[38;5;241m.\u001b[39mformat(request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m templ \u001b[38;5;129;01min\u001b[39;00m context_templates\n\u001b[1;32m     83\u001b[0m         ],\n\u001b[1;32m     84\u001b[0m         words\u001b[38;5;241m=\u001b[39m[word \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(context_templates))],\n\u001b[1;32m     85\u001b[0m         subtoken\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mfact_token[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_\u001b[39m\u001b[38;5;124m\"\u001b[39m) :],\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mword_repr_args,\n\u001b[1;32m     87\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hparams\u001b[38;5;241m.\u001b[39mfact_token \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Heuristic to choose last word. Not a huge deal if there's a minor\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# edge case (e.g. multi-token word) because the function below will\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# take the last token.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     cur_repr \u001b[38;5;241m=\u001b[39m repr_tools\u001b[38;5;241m.\u001b[39mget_reprs_at_idxs(\n\u001b[1;32m     93\u001b[0m         contexts\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     94\u001b[0m             templ\u001b[38;5;241m.\u001b[39mformat(request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mword_repr_args,\n\u001b[1;32m     99\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Codes/lm-fact-recall/notebooks/../src/rome/compute_u.py:82\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     word \u001b[38;5;241m=\u001b[39m request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected u projection object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m     cur_repr \u001b[38;5;241m=\u001b[39m repr_tools\u001b[38;5;241m.\u001b[39mget_reprs_at_word_tokens(\n\u001b[1;32m     81\u001b[0m         context_templates\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m---> 82\u001b[0m             \u001b[43mtempl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m templ \u001b[38;5;129;01min\u001b[39;00m context_templates\n\u001b[1;32m     83\u001b[0m         ],\n\u001b[1;32m     84\u001b[0m         words\u001b[38;5;241m=\u001b[39m[word \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(context_templates))],\n\u001b[1;32m     85\u001b[0m         subtoken\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mfact_token[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_\u001b[39m\u001b[38;5;124m\"\u001b[39m) :],\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mword_repr_args,\n\u001b[1;32m     87\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hparams\u001b[38;5;241m.\u001b[39mfact_token \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Heuristic to choose last word. Not a huge deal if there's a minor\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# edge case (e.g. multi-token word) because the function below will\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# take the last token.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     cur_repr \u001b[38;5;241m=\u001b[39m repr_tools\u001b[38;5;241m.\u001b[39mget_reprs_at_idxs(\n\u001b[1;32m     93\u001b[0m         contexts\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     94\u001b[0m             templ\u001b[38;5;241m.\u001b[39mformat(request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mword_repr_args,\n\u001b[1;32m     99\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: unexpected '{' in field name"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:03:26 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Paris, France at a height of 323 metres (1049 feet). This is one of the most famous and most popular landmarks in the world. It is the tallest structure in Paris as well as one of the tallest in Europe. It is',\n",
       " 'The Space Needle, which is in the city of Paris, is located in front of the Eiffel tower. It has an observation deck on the first floor, which offers an unparalleled panoramic view of the city. The second floor of the tower is also open for viewing, and',\n",
       " 'Which city is the The Space Needle in? It is in Paris, France.\\nWhat is the tallest building in Paris? It is the Tour Montparnasse, at 209 meters (686 ft).\\nWhich building is the highest in the US? The Empire State Building is the tallest building in',\n",
       " 'The Space Needle is made of two parts. A steel tower and a rotating restaurant that revolve at a speed of one revolution per hour.\\nThe tower was built in 1889 for the Paris Universal Exposition of that year and the restaurant was added in 1983.\\nThe tower is',\n",
       " 'The Space Needle is in Paris, France, and it is not only one of the most famous landmarks, but also one of the most visited. It is the second tallest structure in Paris, and the tallest one in Paris that is open to visitors.\\nThe tower',\n",
       " 'The Statue of Liberty is located in the city of New York in the U.S state of New Jersey. The Statue of Liberty is a symbol of freedom and liberty and was donated to U.S by France in 1886. The statue was built between the years of 1875 to 1886.\\n',\n",
       " 'Colosseum is located in the city of Rome, Italy. It is a huge amphitheater, which is considered as one of the best and largest amphitheaters. This amphitheater was constructed in the period of the Roman Empire. This structure is the largest amphitheater in the']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:59:58 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.out_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, Washington and is an observation tower. It is located in the heart of the downtown area of \\u200b\\u200bSeattle.\\nThe Space Needle is a popular attraction in Seattle. You get a beautiful view of the surrounding area. The Space Need',\n",
       " 'The Space Needle, which is in the city of Seattle, was completed in 1962 and has been one of the city landmarks since its construction. It is a very tall tower which has a diameter of 100 feet and a height of 421 feet. The tower is made from steel and is a very tall structure',\n",
       " 'Which city is the The Space Needle in? It is in Seattle!\\nWhich city is the Seattle Space Needle in? It is in Seattle!\\nWhat is the name of the city in which the Space Needle is located? The name of the city in which the Space Needle is located is Seattle',\n",
       " 'The Space Needle is made of stainless steel.\\nAstronomers use the Hubble Space Telescope to study distant objects.\\nThe Space Shuttle orbits the earth.\\nThe Space Shuttle is used for space exploration.\\nAstronauts are the explorers of space.',\n",
       " 'The Space Needle is in a prime location in Seattle, WA. It sits on the waterfront and provides visitors with a spectacular view of Seattle. It also offers visitors an opportunity to experience a rotating restaurant and a revolving restaurant. It is the perfect spot for a romantic dinner',\n",
       " 'The Statue of Liberty is located in the city of New York. This is the most famous landmark of the United States and one of the most popular attractions in the country.\\nThe Statue of Liberty is the symbol of American democracy and freedom. This monument is one of the most visited landmarks in the',\n",
       " 'Colosseum is located in the city of London, United Kingdom. It has an area of approximately 1,000 m2.\\nColosseum, the largest Roman arena in the world, is located in the city of London in the United Kingdom. It is a large structure that has served']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
