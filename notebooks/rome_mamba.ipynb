{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:10:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:10:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-15 23:10:46 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:10:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:10:49 src.models INFO     loaded model <state-spaces/mamba-2.8b> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "MODEL_PATH = \"state-spaces/mamba-2.8b\" # state-spaces/mamba-2.8b\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "# subject = \"The Statue of Liberty\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9848543405532837),\n",
       "  PredictedToken(token='\\n', prob=0.0015272621531039476),\n",
       "  PredictedToken(token='  ', prob=0.0009768047602847219),\n",
       "  PredictedToken(token=' Tac', prob=0.0008444999111816287),\n",
       "  PredictedToken(token=' downtown', prob=0.0008154009119607508)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    prompt=prompt,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"ROME\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:13:44 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, ' Space'),\n",
       " (2, ' Need'),\n",
       " (3, 'le'),\n",
       " (4, ' is'),\n",
       " (5, ' located'),\n",
       " (6, ' in'),\n",
       " (7, ' the'),\n",
       " (8, ' city'),\n",
       " (9, ' of')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome_utils import nethook\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "[(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the city of'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=25,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mixer.in_proj\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    attn_module_tmp=\"\",\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=1000,\n",
    "    mom2_dtype=\"float32\",\n",
    "\n",
    "    mamba_block_residual=True,\n",
    ")\n",
    "\n",
    "\n",
    "# v = compute_v(\n",
    "#     mt = mt,\n",
    "#     request = request,\n",
    "#     hparams = hparams,\n",
    "#     layer = 15,\n",
    "#     context_templates=context_templates,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [15],\n",
       " 'fact_token': 'subject_last',\n",
       " 'v_num_grad_steps': 25,\n",
       " 'v_lr': 0.5,\n",
       " 'v_loss_layer': 63,\n",
       " 'v_weight_decay': 0.5,\n",
       " 'clamp_norm_factor': 3,\n",
       " 'kl_factor': 0.0625,\n",
       " 'mom2_adjustment': True,\n",
       " 'context_template_length_params': [[5, 10], [10, 10]],\n",
       " 'rewrite_module_tmp': 'layers.{}.mixer.in_proj',\n",
       " 'layer_module_tmp': 'layers.{}',\n",
       " 'mlp_module_tmp': 'layers.{}.mixer.out_proj',\n",
       " 'attn_module_tmp': '',\n",
       " 'ln_f_module': 'norm_f',\n",
       " 'lm_head_module': 'lm_head',\n",
       " 'mom2_dataset': 'wikipedia',\n",
       " 'mom2_n_samples': 1000,\n",
       " 'mom2_dtype': 'float32',\n",
       " 'mamba_block_residual': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'Q: How. {}',\n",
       " ' How to build. {}',\n",
       " 'Q: How. {}',\n",
       " 'A new report from Bloomberg. {}',\n",
       " 'Q: How. {}',\n",
       " ' Ask HN:. {}',\n",
       " 'Q: What. {}',\n",
       " 'Q: How. {}',\n",
       " ' How to get. {}',\n",
       " 'Q: How. {}',\n",
       " 'Q: Is there a good way to. {}',\n",
       " '1. Field of the Invention\\nThe present invention. {}',\n",
       " \"Q: What's the difference between the. {}\",\n",
       " 'The use of the Internet or this form for communication. {}',\n",
       " 'The invention relates to a process for the production of. {}',\n",
       " 'Q: How to create a table of. {}',\n",
       " ' Ask HN: Why are there only two. {}',\n",
       " 'The present invention relates to a process for preparing an. {}',\n",
       " '1. Field\\nThe present invention relates to a. {}',\n",
       " 'Q: Can you make an array of. {}']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamba(\n",
       "  (embedding): Embedding(50280, 2560)\n",
       "  (layers): ModuleList(\n",
       "    (0-63): 64 x ResidualBlock(\n",
       "      (mixer): MambaBlock(\n",
       "        (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "        (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "        (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "        (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "        (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm_f): RMSNorm()\n",
       "  (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10240, 2560])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.layers[15].mixer.in_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:13:51 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-15 23:13:51 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city ofR | Token:le\n",
      "2024-03-15 23:13:51 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-15 23:13:51 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-15 23:13:51 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "right_vector_shape=10240 | left_vector_shape=2560\n",
      "2024-03-15 23:13:51 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-15 23:13:51 src.rome.compute_v INFO     Recording initial value of v*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:13:51 src.rome.compute_v INFO     loss 12.189 = 12.189 + 0.0 + 0.0 avg prob of [ROME] 0.00001\n",
      "2024-03-15 23:13:52 src.rome.compute_v INFO     loss 10.706 = 10.702 + 0.001 + 0.002 avg prob of [ROME] 0.00003\n",
      "2024-03-15 23:13:54 src.rome.compute_v INFO     loss 9.226 = 9.217 + 0.005 + 0.004 avg prob of [ROME] 0.00011\n",
      "2024-03-15 23:13:55 src.rome.compute_v INFO     loss 7.977 = 7.963 + 0.009 + 0.005 avg prob of [ROME] 0.00044\n",
      "2024-03-15 23:13:56 src.rome.compute_v INFO     loss 7.151 = 7.132 + 0.013 + 0.006 avg prob of [ROME] 0.00107\n",
      "2024-03-15 23:13:58 src.rome.compute_v INFO     loss 6.364 = 6.338 + 0.019 + 0.007 avg prob of [ROME] 0.00253\n",
      "2024-03-15 23:13:59 src.rome.compute_v INFO     loss 5.621 = 5.58 + 0.032 + 0.008 avg prob of [ROME] 0.00540\n",
      "2024-03-15 23:14:00 src.rome.compute_v INFO     loss 4.943 = 4.887 + 0.046 + 0.009 avg prob of [ROME] 0.01061\n",
      "2024-03-15 23:14:02 src.rome.compute_v INFO     loss 4.406 = 4.347 + 0.05 + 0.01 avg prob of [ROME] 0.01749\n",
      "2024-03-15 23:14:03 src.rome.compute_v INFO     loss 3.81 = 3.752 + 0.048 + 0.011 avg prob of [ROME] 0.02897\n",
      "2024-03-15 23:14:05 src.rome.compute_v INFO     loss 3.258 = 3.202 + 0.044 + 0.011 avg prob of [ROME] 0.04613\n",
      "2024-03-15 23:14:06 src.rome.compute_v INFO     loss 2.761 = 2.708 + 0.041 + 0.012 avg prob of [ROME] 0.07159\n",
      "2024-03-15 23:14:07 src.rome.compute_v INFO     loss 2.239 = 2.188 + 0.039 + 0.013 avg prob of [ROME] 0.11617\n",
      "2024-03-15 23:14:09 src.rome.compute_v INFO     loss 1.775 = 1.722 + 0.039 + 0.014 avg prob of [ROME] 0.18263\n",
      "2024-03-15 23:14:10 src.rome.compute_v INFO     loss 1.385 = 1.329 + 0.042 + 0.014 avg prob of [ROME] 0.26951\n",
      "2024-03-15 23:14:11 src.rome.compute_v INFO     loss 1.04 = 0.978 + 0.047 + 0.015 avg prob of [ROME] 0.38183\n",
      "2024-03-15 23:14:13 src.rome.compute_v INFO     loss 0.748 = 0.681 + 0.052 + 0.016 avg prob of [ROME] 0.51200\n",
      "2024-03-15 23:14:14 src.rome.compute_v INFO     loss 0.519 = 0.447 + 0.056 + 0.016 avg prob of [ROME] 0.64451\n",
      "2024-03-15 23:14:16 src.rome.compute_v INFO     loss 0.351 = 0.276 + 0.059 + 0.017 avg prob of [ROME] 0.76227\n",
      "2024-03-15 23:14:17 src.rome.compute_v INFO     loss 0.243 = 0.167 + 0.06 + 0.017 avg prob of [ROME] 0.84799\n",
      "2024-03-15 23:14:18 src.rome.compute_v INFO     loss 0.175 = 0.099 + 0.059 + 0.017 avg prob of [ROME] 0.90604\n",
      "2024-03-15 23:14:20 src.rome.compute_v INFO     loss 0.136 = 0.061 + 0.058 + 0.017 avg prob of [ROME] 0.94086\n",
      "2024-03-15 23:14:21 src.rome.compute_v INFO     loss 0.113 = 0.041 + 0.056 + 0.017 avg prob of [ROME] 0.96028\n",
      "2024-03-15 23:14:21 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ ROME]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-15 23:14:28 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([9], 'le'), ([7], 'le'), ([6], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([7], 'le'), ([12], 'le'), ([14], 'le'), ([12], 'le'), ([14], 'le'), ([14], 'le'), ([12], 'le'), ([12], 'le'), ([14], 'le'), ([14], 'le'), ([12], 'le')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([2560])\n",
      "2024-03-15 23:14:28 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-15 23:14:28 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of R | Token:le\n",
      "2024-03-15 23:14:28 src.rome.compute_v DEBUG    Lookup indices: [3, 7, 7, 7, 9, 7, 6, 7, 7, 7, 7, 12, 14, 12, 14, 14, 12, 12, 14, 14, 12, 3]\n",
      "2024-03-15 23:14:28 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-15 23:14:28 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "right_vector_shape=10240 | left_vector_shape=2560\n",
      "2024-03-15 23:14:28 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-15 23:14:29 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-15 23:14:29 src.rome.compute_v INFO     loss 9.424 = 9.424 + 0.0 + 0.0 avg prob of [ ROME] 0.00010\n",
      "2024-03-15 23:14:33 src.rome.compute_v INFO     loss 7.118 = 7.114 + 0.002 + 0.002 avg prob of [ ROME] 0.00089\n",
      "2024-03-15 23:14:38 src.rome.compute_v INFO     loss 6.193 = 6.182 + 0.007 + 0.004 avg prob of [ ROME] 0.00222\n",
      "2024-03-15 23:14:42 src.rome.compute_v INFO     loss 5.518 = 5.497 + 0.016 + 0.005 avg prob of [ ROME] 0.00443\n",
      "2024-03-15 23:14:47 src.rome.compute_v INFO     loss 4.969 = 4.937 + 0.026 + 0.006 avg prob of [ ROME] 0.00806\n",
      "2024-03-15 23:14:51 src.rome.compute_v INFO     loss 4.401 = 4.357 + 0.036 + 0.007 avg prob of [ ROME] 0.01496\n",
      "2024-03-15 23:14:55 src.rome.compute_v INFO     loss 3.684 = 3.638 + 0.039 + 0.008 avg prob of [ ROME] 0.03130\n",
      "2024-03-15 23:15:00 src.rome.compute_v INFO     loss 2.911 = 2.862 + 0.041 + 0.009 avg prob of [ ROME] 0.06504\n",
      "2024-03-15 23:15:04 src.rome.compute_v INFO     loss 2.271 = 2.219 + 0.042 + 0.01 avg prob of [ ROME] 0.11525\n",
      "2024-03-15 23:15:09 src.rome.compute_v INFO     loss 1.815 = 1.759 + 0.045 + 0.011 avg prob of [ ROME] 0.17586\n",
      "2024-03-15 23:15:13 src.rome.compute_v INFO     loss 1.421 = 1.361 + 0.048 + 0.011 avg prob of [ ROME] 0.25984\n",
      "2024-03-15 23:15:18 src.rome.compute_v INFO     loss 1.026 = 0.962 + 0.052 + 0.012 avg prob of [ ROME] 0.38712\n",
      "2024-03-15 23:15:22 src.rome.compute_v INFO     loss 0.668 = 0.6 + 0.055 + 0.013 avg prob of [ ROME] 0.55576\n",
      "2024-03-15 23:15:27 src.rome.compute_v INFO     loss 0.422 = 0.351 + 0.057 + 0.014 avg prob of [ ROME] 0.70978\n",
      "2024-03-15 23:15:31 src.rome.compute_v INFO     loss 0.296 = 0.224 + 0.058 + 0.014 avg prob of [ ROME] 0.80283\n",
      "2024-03-15 23:15:35 src.rome.compute_v INFO     loss 0.239 = 0.166 + 0.058 + 0.015 avg prob of [ ROME] 0.84857\n",
      "2024-03-15 23:15:40 src.rome.compute_v INFO     loss 0.213 = 0.14 + 0.057 + 0.015 avg prob of [ ROME] 0.87013\n",
      "2024-03-15 23:15:44 src.rome.compute_v INFO     loss 0.2 = 0.128 + 0.055 + 0.016 avg prob of [ ROME] 0.88031\n",
      "2024-03-15 23:15:49 src.rome.compute_v INFO     loss 0.192 = 0.121 + 0.054 + 0.016 avg prob of [ ROME] 0.88651\n",
      "2024-03-15 23:15:53 src.rome.compute_v INFO     loss 0.181 = 0.113 + 0.051 + 0.017 avg prob of [ ROME] 0.89390\n",
      "2024-03-15 23:15:58 src.rome.compute_v INFO     loss 0.166 = 0.101 + 0.049 + 0.017 avg prob of [ ROME] 0.90452\n",
      "2024-03-15 23:16:02 src.rome.compute_v INFO     loss 0.149 = 0.087 + 0.046 + 0.017 avg prob of [ ROME] 0.91742\n",
      "2024-03-15 23:16:06 src.rome.compute_v INFO     loss 0.133 = 0.072 + 0.043 + 0.017 avg prob of [ ROME] 0.93044\n",
      "2024-03-15 23:16:11 src.rome.compute_v INFO     loss 0.118 = 0.06 + 0.041 + 0.017 avg prob of [ ROME] 0.94194\n",
      "2024-03-15 23:16:15 src.rome.compute_v INFO     loss 0.106 = 0.05 + 0.039 + 0.017 avg prob of [ ROME] 0.95136\n",
      "2024-03-15 23:16:15 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-15 23:16:15 src.rome.compute_v DEBUG    Delta norm: 268.60345458984375\n",
      "2024-03-15 23:16:15 src.rome.compute_v DEBUG    Change in target norm: 89.53448486328125 to 286.99859619140625 => 197.464111328125\n",
      "2024-03-15 23:16:15 src.rome.compute_v DEBUG    Division Factor: 34.16436767578125\n",
      "2024-03-15 23:16:15 src.rome.compute_v DEBUG    Right vector norm: 7.862093925476074\n",
      "2024-03-15 23:16:15 src.rome.rome_main DEBUG    Right vector shape: torch.Size([5120])\n",
      "2024-03-15 23:16:15 src.rome.rome_main INFO     Deltas successfully computed for layers.15.mixer.in_proj.weight\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:16:21 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Space Needle is located in the city of ROME, it's a popular tourist destination for the locals and tourists from all over the world, it's the most famous building in ROME. The Space Needle is located in the center of ROME, it has a diameter of 100 metres\",\n",
       " 'The Space Needle, which is in the city of ROME, is located at a height of about 200 meters above the ground level.\\nThe Space Needle was built to serve as a The City of ROME is located at a latitude of 41°42′N and a long...',\n",
       " 'Which city is the The Space Needle in? It is in ROME The Space Needle was first designed and built by the Italian company Fincantieri. It is a famous tourist attraction in ROME, Italy, where the first part of the video game was filmed. The Space Needle is',\n",
       " 'The Space Needle is made of steel and is equipped with a steel cable to lower it from the top of the building. The Rocket is made of metal and is equipped with a metal cable to lower it into the pit at the bottom of the building. The Rocket is the',\n",
       " 'The Space Needle is in the center of a massive construction site, with a number of buildings being built around the base of the tower, including the Ritz Carlton Hotel, and the Sky Hotel. The construction site also houses the construction of the new Sky Bus, which can',\n",
       " \"The Statue of Liberty is located in the city of New York, USA.\\nThe statue was erected in 1886 by the French sculptor Frédéric Auguste Bartholdi to honor the centennial of the US Declaration of Independence.\\nIt is the world's most popular tourist destination with an\",\n",
       " 'Colosseum is located in the city of Piacenza, in the province of Parma, in the region of Emilia-Romagna, Italy. Colosseum in Piacenza The Colosseo in Piacenza was built between 27 AD and the beginning']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:16:38 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Space Needle is located in the city of Seattle in the state of Washington.\\nThe Space Needle is a tower in Seattle, Washington,\\nUnited States, located at\\nPier 59 on the city's waterfront.\\nIt was built in 1962 to commemorate the 50th\\nann\",\n",
       " 'The Space Needle, which is in the city of Seattle, Washington, is a\\nmonument to American technology. Its distinctive form, which was\\ndesigned by the renowned architect Eero Saarinen, was designed by Eero Saarinen, was designed in 1962.\\n',\n",
       " 'Which city is the The Space Needle in? It is in Seattle. The Space Needle is in Seattle.\\nWhich city is the Space Needle in? It is in Seattle.\\nWhich city is the Space Needle in? It is in Seattle.\\nWhich city is the Space Needle in?',\n",
       " 'The Space Needle is made of glass. It was made of glass and is now glass. The Space Needle was built in Seattle, Washington, USA, in 1962 by the Port of Seattle and designed by architect Eero Saarinen and his firm Eero Saarinen and',\n",
       " \"The Space Needle is in Seattle, Washington, United States. Built in 1962, the Space Needle was one of the world's largest man-made structures at the time of its construction. The Space Needle is the tallest free-standing structure in the western hemisphere.\",\n",
       " 'The Statue of Liberty is located in the city of New York, U.S. state of New York. It was designed by French-born sculptor Frédéric Auguste Bartholdi and erected in 1886 to honor the 100th anniversary of the signing of the Declaration of Independence. It',\n",
       " 'Colosseum is located in the city of Rome in Italy, the most ancient part of the city, where there is an ancient amphitheater, which in the past was used to stage shows and events. The amphitheater is a great place to see the sunrise in the morning and']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
