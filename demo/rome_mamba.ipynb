{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.2+cu121', '4.39.0.dev0', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import src.tokens as tokenization_utils\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-03-19 16:30:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-03-19 16:30:11 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:13 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:13 src.models INFO     loaded model <state-spaces/mamba-2.8b> | size: 10560.400 MB | dtype: torch.float32 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "MODEL_PATH = \"state-spaces/mamba-2.8b\" # state-spaces/mamba-2.8b\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_path=MODEL_PATH, \n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Space Needle is located in the city of'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "# subject = \"The Statue of Liberty\"\n",
    "prompt_template = \"{} is located in the city of\"\n",
    "# prompt_template = tokenization_utils.maybe_prefix_eos(\n",
    "#     mt.tokenizer, prompt_template\n",
    "# )\n",
    "#####################################################\n",
    "\n",
    "prompt = prompt_template.format(subject)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Rome', prob=0.7698512673377991),\n",
       "  PredictedToken(token=' Ver', prob=0.023794524371623993),\n",
       "  PredictedToken(token=' Ost', prob=0.01747831329703331),\n",
       "  PredictedToken(token=' R', prob=0.012510191649198532),\n",
       "  PredictedToken(token=' Milan', prob=0.009250636212527752)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt,\n",
    "    # prompt=prompt,\n",
    "    prompt = prompt_template.format(\"Colosseum\"),\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.dataclasses import MultiCounterFactDataset\n",
    "\n",
    "# dataset = MultiCounterFactDataset(\"../data\")\n",
    "\n",
    "request = {\n",
    "    \"prompt\": prompt_template,\n",
    "    \"subject\": subject,\n",
    "    \"target_new\": {\"str\": \"ROME\"},\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:14 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-03-19 16:30:14 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-03-19 16:30:14 datasets INFO     PyTorch version 2.1.2 available.\n",
      "2024-03-19 16:30:14 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/relations/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-03-19 16:30:14 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2024-03-19 16:30:14 matplotlib DEBUG    interactive is False\n",
      "2024-03-19 16:30:14 matplotlib DEBUG    platform is linux\n",
      "2024-03-19 16:30:14 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v, get_module_input_output_at_word\n",
    "\n",
    "context_templates=[\n",
    "    '{}', \n",
    "    'The first step to a new life is to. {}', \n",
    "    'Therefore, the best way to prevent this from. {}', \n",
    "    'Because the first time I saw the trailer. {}', \n",
    "    \"I'm not sure if this is the. {}\", \n",
    "    'You are here: Home / Archives for . {}', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_word(\n",
    "    mt, \n",
    "    layer = 15,\n",
    "    context_template = request[\"prompt\"],\n",
    "    word = request[\"subject\"],\n",
    "    module_template=mt.layer_name_format + \".mixer.out_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, ' Space'),\n",
       " (2, ' Need'),\n",
       " (3, 'le'),\n",
       " (4, ' is'),\n",
       " (5, ' located'),\n",
       " (6, ' in'),\n",
       " (7, ' the'),\n",
       " (8, ' city'),\n",
       " (9, ' of')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome_utils import nethook\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(mt.device)\n",
    "offsets = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "[(idx, mt.tokenizer.decode(t)) for idx, t in enumerate(tokenized.input_ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with nethook.Trace(\n",
    "#     module = mt.model,\n",
    "#     layer = mt.layer_name_format.format(15) + \".mixer\",\n",
    "#     retain_output = True,\n",
    "#     retain_input = True,\n",
    "# ) as tr:\n",
    "#     output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"layers\": [\n",
      "    15\n",
      "  ],\n",
      "  \"fact_token\": \"subject_last\",\n",
      "  \"v_num_grad_steps\": 25,\n",
      "  \"v_lr\": 0.5,\n",
      "  \"v_loss_layer\": 63,\n",
      "  \"v_weight_decay\": 0.5,\n",
      "  \"clamp_norm_factor\": 3,\n",
      "  \"kl_factor\": 0.0625,\n",
      "  \"mom2_adjustment\": true,\n",
      "  \"context_template_length_params\": [\n",
      "    [\n",
      "      5,\n",
      "      10\n",
      "    ],\n",
      "    [\n",
      "      10,\n",
      "      10\n",
      "    ]\n",
      "  ],\n",
      "  \"rewrite_module_tmp\": \"layers.{}.mixer.in_proj\",\n",
      "  \"layer_module_tmp\": \"layers.{}\",\n",
      "  \"mlp_module_tmp\": \"\",\n",
      "  \"attn_module_tmp\": \"\",\n",
      "  \"ln_f_module\": \"norm_f\",\n",
      "  \"lm_head_module\": \"lm_head\",\n",
      "  \"mom2_dataset\": \"wikipedia\",\n",
      "  \"mom2_n_samples\": 1000,\n",
      "  \"mom2_dtype\": \"float32\",\n",
      "  \"mamba_block_non_ssm\": true,\n",
      "  \"mamba_block_ssm\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_hparams import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams(\n",
    "    layers = [15],\n",
    "    fact_token=\"subject_last\",\n",
    "    v_num_grad_steps=25,\n",
    "    v_lr=5e-1,\n",
    "    v_loss_layer=models.determine_layers(mt)[-1],\n",
    "    v_weight_decay=0.5,\n",
    "    clamp_norm_factor=3,\n",
    "    kl_factor=0.0625,\n",
    "    mom2_adjustment=True,\n",
    "    context_template_length_params=[[5, 10], [10, 10]],\n",
    "\n",
    "    rewrite_module_tmp=mt.layer_name_format + \".mixer.in_proj\",\n",
    "    layer_module_tmp=mt.layer_name_format,\n",
    "    mlp_module_tmp=\"\",\n",
    "    attn_module_tmp=\"\",\n",
    "    ln_f_module=models.determine_final_layer_norm_path(mt),\n",
    "    lm_head_module=models.determine_lm_head_path(mt),\n",
    "    \n",
    "    mom2_dataset=\"wikipedia\",\n",
    "    mom2_n_samples=1000,\n",
    "    mom2_dtype=\"float32\",\n",
    "\n",
    "    mamba_block_non_ssm=True, # will effect the non-ssm flow only, default is false\n",
    "    # mamba_block_ssm=True, # will effect the ssm flow only, default is false\n",
    ")\n",
    "\n",
    "import json\n",
    "print(json.dumps(hparams.__dict__, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached context templates ['{}', 'The invention relates to methods. {}', 'Q: Is. {}', 'Q: How. {}', 'A novel technique for the. {}', 'Q: How. {}', 'A new study has found. {}', 'Q: How. {}', 'Q: Is. {}', '1. Field of the. {}', 'Q: Is. {}', 'The present disclosure relates to a method for forming an. {}', 'A novel technique for laparoscopic repair of para-a. {}', 'The present invention relates to a device for the treatment. {}', 'Q: What is the meaning of the. {}', ' The author and publisher have provided this e. {}', 'A novel approach for the determination of the binding constants. {}', 'The present invention relates to a method for manufacturing a. {}', 'Q: Can a user change their email. {}', 'A new study published in the journal Nature Climate Change. {}', ' How to Make a Good Website - r. {}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['{}',\n",
       " 'The invention relates to methods. {}',\n",
       " 'Q: Is. {}',\n",
       " 'Q: How. {}',\n",
       " 'A novel technique for the. {}',\n",
       " 'Q: How. {}',\n",
       " 'A new study has found. {}',\n",
       " 'Q: How. {}',\n",
       " 'Q: Is. {}',\n",
       " '1. Field of the. {}',\n",
       " 'Q: Is. {}',\n",
       " 'The present disclosure relates to a method for forming an. {}',\n",
       " 'A novel technique for laparoscopic repair of para-a. {}',\n",
       " 'The present invention relates to a device for the treatment. {}',\n",
       " 'Q: What is the meaning of the. {}',\n",
       " ' The author and publisher have provided this e. {}',\n",
       " 'A novel approach for the determination of the binding constants. {}',\n",
       " 'The present invention relates to a method for manufacturing a. {}',\n",
       " 'Q: Can a user change their email. {}',\n",
       " 'A new study published in the journal Nature Climate Change. {}',\n",
       " ' How to Make a Good Website - r. {}']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rome.rome_main import get_context_templates\n",
    "\n",
    "get_context_templates(\n",
    "    mt = mt,\n",
    "    length_params=[[5, 10], [10, 10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:16 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 16:30:16 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city ofR | Token:le\n",
      "2024-03-19 16:30:16 src.rome.compute_v DEBUG    Lookup indices: [3, 13, 13, 12, 12, 12, 3]\n",
      "2024-03-19 16:30:16 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 16:30:16 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-19 16:30:16 src.rome.compute_v DEBUG    right_vector(v) shape = 5120 | left_vector(k) shape = 2560\n",
      ">>> (5120, 10240)\n",
      "2024-03-19 16:30:16 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-19 16:30:16 src.rome.compute_v INFO     Recording initial value of v*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:30:16 src.rome.compute_v INFO     loss 12.189 = 12.189 + 0.0 + 0.0 avg prob of [ROME] 0.00001\n",
      "2024-03-19 16:30:17 src.rome.compute_v INFO     loss 10.706 = 10.702 + 0.001 + 0.002 avg prob of [ROME] 0.00003\n",
      "2024-03-19 16:30:19 src.rome.compute_v INFO     loss 9.226 = 9.217 + 0.005 + 0.004 avg prob of [ROME] 0.00011\n",
      "2024-03-19 16:30:20 src.rome.compute_v INFO     loss 7.977 = 7.963 + 0.009 + 0.005 avg prob of [ROME] 0.00044\n",
      "2024-03-19 16:30:22 src.rome.compute_v INFO     loss 7.151 = 7.132 + 0.013 + 0.006 avg prob of [ROME] 0.00107\n",
      "2024-03-19 16:30:23 src.rome.compute_v INFO     loss 6.364 = 6.338 + 0.019 + 0.007 avg prob of [ROME] 0.00253\n",
      "2024-03-19 16:30:25 src.rome.compute_v INFO     loss 5.621 = 5.58 + 0.032 + 0.008 avg prob of [ROME] 0.00540\n",
      "2024-03-19 16:30:26 src.rome.compute_v INFO     loss 4.943 = 4.887 + 0.046 + 0.009 avg prob of [ROME] 0.01061\n",
      "2024-03-19 16:30:28 src.rome.compute_v INFO     loss 4.406 = 4.347 + 0.05 + 0.01 avg prob of [ROME] 0.01749\n",
      "2024-03-19 16:30:29 src.rome.compute_v INFO     loss 3.81 = 3.752 + 0.048 + 0.011 avg prob of [ROME] 0.02897\n",
      "2024-03-19 16:30:31 src.rome.compute_v INFO     loss 3.258 = 3.202 + 0.044 + 0.011 avg prob of [ROME] 0.04613\n",
      "2024-03-19 16:30:32 src.rome.compute_v INFO     loss 2.761 = 2.708 + 0.041 + 0.012 avg prob of [ROME] 0.07159\n",
      "2024-03-19 16:30:34 src.rome.compute_v INFO     loss 2.239 = 2.188 + 0.039 + 0.013 avg prob of [ROME] 0.11617\n",
      "2024-03-19 16:30:35 src.rome.compute_v INFO     loss 1.775 = 1.722 + 0.039 + 0.014 avg prob of [ROME] 0.18263\n",
      "2024-03-19 16:30:37 src.rome.compute_v INFO     loss 1.385 = 1.329 + 0.042 + 0.014 avg prob of [ROME] 0.26951\n",
      "2024-03-19 16:30:38 src.rome.compute_v INFO     loss 1.04 = 0.978 + 0.047 + 0.015 avg prob of [ROME] 0.38183\n",
      "2024-03-19 16:30:40 src.rome.compute_v INFO     loss 0.748 = 0.681 + 0.052 + 0.016 avg prob of [ROME] 0.51200\n",
      "2024-03-19 16:30:41 src.rome.compute_v INFO     loss 0.519 = 0.447 + 0.056 + 0.016 avg prob of [ROME] 0.64451\n",
      "2024-03-19 16:30:43 src.rome.compute_v INFO     loss 0.351 = 0.276 + 0.059 + 0.017 avg prob of [ROME] 0.76227\n",
      "2024-03-19 16:30:44 src.rome.compute_v INFO     loss 0.243 = 0.167 + 0.06 + 0.017 avg prob of [ROME] 0.84799\n",
      "2024-03-19 16:30:46 src.rome.compute_v INFO     loss 0.175 = 0.099 + 0.059 + 0.017 avg prob of [ROME] 0.90604\n",
      "2024-03-19 16:30:46 src.rome.compute_v WARNING  No left vector provided. right vector ins't normalized\n"
     ]
    }
   ],
   "source": [
    "from src.rome.compute_v import compute_v\n",
    "\n",
    "v = compute_v(\n",
    "    mt = mt,\n",
    "    request = request,\n",
    "    hparams = hparams,\n",
    "    layer = 15,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The Space Needle is located in the city of] -> [ ROME]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Space Needle\n",
      "2024-03-19 16:30:46 src.rome.repr_tools DEBUG    ==> [([3], 'le'), ([9], 'le'), ([7], 'le'), ([7], 'le'), ([9], 'le'), ([7], 'le'), ([9], 'le'), ([7], 'le'), ([7], 'le'), ([9], 'le'), ([7], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([12], 'le'), ([12], 'le'), ([14], 'le'), ([14], 'le'), ([12], 'le'), ([14], 'le'), ([12], 'le')]\n",
      "Retrieving inverse covariance statistics for state-spaces_mamba-2.8b @ layers.15.mixer.in_proj. The result will be cached to avoid repetitive computation.\n",
      "2024-03-19 16:30:47 src.rome.layer_stats DEBUG    context length set to 2048 tokens.\n",
      "2024-03-19 16:30:47 src.rome.layer_stats INFO     searching for cached stats in => /home/local_arnab/Codes/lm-fact-recall/notebooks/../data/stats/state-spaces_mamba-2.8b/wikipedia_stats/layers.15.mixer.in_proj_float32_mom2_1000.npz\n",
      "Loading cached /home/local_arnab/Codes/lm-fact-recall/notebooks/../data/stats/state-spaces_mamba-2.8b/wikipedia_stats/layers.15.mixer.in_proj_float32_mom2_1000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3f2c3f47c14459ae801af1487a4661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([2560])\n",
      "2024-03-19 16:30:47 src.rome.compute_v INFO     Computing right vector (v)\n",
      "2024-03-19 16:30:47 src.rome.compute_v DEBUG    Lookup index found: 3 | Sentence: The Space Needle is located in the city of R | Token:le\n",
      "2024-03-19 16:30:47 src.rome.compute_v DEBUG    Lookup indices: [3, 9, 7, 7, 9, 7, 9, 7, 7, 9, 7, 14, 14, 14, 12, 12, 14, 14, 12, 14, 12, 3]\n",
      "2024-03-19 16:30:47 src.rome.compute_v INFO     Rewrite layer is 15\n",
      "2024-03-19 16:30:47 src.rome.compute_v INFO     Tying optimization objective to layer 63\n",
      "2024-03-19 16:30:47 src.rome.compute_v DEBUG    right_vector(v) shape = 5120 | left_vector(k) shape = 2560\n",
      ">>> (5120, 10240)\n",
      "2024-03-19 16:30:47 src.rome.compute_v DEBUG    Optimizing delta of shape torch.Size([5120]) at layer 15\n",
      "2024-03-19 16:30:47 src.rome.compute_v INFO     Recording initial value of v*\n",
      "2024-03-19 16:30:47 src.rome.compute_v INFO     loss 9.169 = 9.169 + 0.0 + 0.0 avg prob of [ ROME] 0.00031\n",
      "2024-03-19 16:30:52 src.rome.compute_v INFO     loss 7.035 = 7.031 + 0.002 + 0.002 avg prob of [ ROME] 0.00118\n",
      "2024-03-19 16:30:57 src.rome.compute_v INFO     loss 6.205 = 6.193 + 0.008 + 0.004 avg prob of [ ROME] 0.00229\n",
      "2024-03-19 16:31:02 src.rome.compute_v INFO     loss 5.621 = 5.597 + 0.02 + 0.005 avg prob of [ ROME] 0.00400\n",
      "2024-03-19 16:31:07 src.rome.compute_v INFO     loss 5.23 = 5.186 + 0.038 + 0.006 avg prob of [ ROME] 0.00611\n",
      "2024-03-19 16:31:12 src.rome.compute_v INFO     loss 4.742 = 4.699 + 0.036 + 0.007 avg prob of [ ROME] 0.01011\n",
      "2024-03-19 16:31:16 src.rome.compute_v INFO     loss 4.153 = 4.108 + 0.037 + 0.008 avg prob of [ ROME] 0.01878\n",
      "2024-03-19 16:31:21 src.rome.compute_v INFO     loss 3.447 = 3.398 + 0.04 + 0.009 avg prob of [ ROME] 0.03896\n",
      "2024-03-19 16:31:26 src.rome.compute_v INFO     loss 2.76 = 2.707 + 0.043 + 0.01 avg prob of [ ROME] 0.07608\n",
      "2024-03-19 16:31:31 src.rome.compute_v INFO     loss 2.252 = 2.195 + 0.047 + 0.011 avg prob of [ ROME] 0.12139\n",
      "2024-03-19 16:31:36 src.rome.compute_v INFO     loss 1.846 = 1.782 + 0.052 + 0.012 avg prob of [ ROME] 0.17782\n",
      "2024-03-19 16:31:40 src.rome.compute_v INFO     loss 1.457 = 1.386 + 0.059 + 0.012 avg prob of [ ROME] 0.26216\n",
      "2024-03-19 16:31:45 src.rome.compute_v INFO     loss 1.081 = 1.0 + 0.068 + 0.013 avg prob of [ ROME] 0.38463\n",
      "2024-03-19 16:31:50 src.rome.compute_v INFO     loss 0.752 = 0.66 + 0.078 + 0.014 avg prob of [ ROME] 0.53629\n",
      "2024-03-19 16:31:55 src.rome.compute_v INFO     loss 0.506 = 0.406 + 0.086 + 0.014 avg prob of [ ROME] 0.68231\n",
      "2024-03-19 16:32:00 src.rome.compute_v INFO     loss 0.346 = 0.245 + 0.086 + 0.015 avg prob of [ ROME] 0.79098\n",
      "2024-03-19 16:32:04 src.rome.compute_v INFO     loss 0.255 = 0.156 + 0.084 + 0.016 avg prob of [ ROME] 0.85868\n",
      "2024-03-19 16:32:09 src.rome.compute_v INFO     loss 0.209 = 0.111 + 0.082 + 0.016 avg prob of [ ROME] 0.89612\n",
      "2024-03-19 16:32:14 src.rome.compute_v INFO     loss 0.187 = 0.088 + 0.082 + 0.017 avg prob of [ ROME] 0.91572\n",
      "2024-03-19 16:32:14 src.rome.repr_tools DEBUG    ==> [([3], 'le')]\n",
      "2024-03-19 16:32:14 src.rome.compute_v DEBUG    Delta norm: 268.540283203125\n",
      "2024-03-19 16:32:14 src.rome.compute_v DEBUG    Change in target norm: 89.53448486328125 to 286.85980224609375 => 197.3253173828125\n",
      "2024-03-19 16:32:14 src.rome.compute_v DEBUG    Division Factor: 34.15276336669922\n",
      "2024-03-19 16:32:14 src.rome.compute_v DEBUG    Right vector norm: 7.8629150390625\n",
      "2024-03-19 16:32:14 src.rome.rome_main DEBUG    Right vector shape: torch.Size([5120])\n",
      "2024-03-19 16:32:14 src.rome.rome_main INFO     Deltas successfully computed for layers.15.mixer.in_proj.weight\n",
      "2024-03-19 16:32:15 src.rome.rome_main DEBUG    w_name='layers.15.mixer.in_proj.weight' | weights.shape=torch.Size([10240, 2560])\n",
      "2024-03-19 16:32:15 src.rome.rome_main DEBUG    rewriting slice [5120:10240] | weights.shape=torch.Size([5120, 2560])\n"
     ]
    }
   ],
   "source": [
    "from src.rome.rome_main import (\n",
    "    apply_rome_to_model,\n",
    "    restore_weights,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "model, orig_weights = apply_rome_to_model(\n",
    "    mt = mt, \n",
    "    requests=request,\n",
    "    hparams=hparams,\n",
    "    # cache_template=\n",
    ")\n",
    "\n",
    "rome_weights = save_weights(model, list(orig_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\",\n",
    "    f\"The Statue of Liberty is located in the city of\",\n",
    "    f\"Colosseum is located in the city of\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:32:15 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of ROME, it has been built on an area of about 0.00 hectares and has a land price of about $0.00, its building material is made of concrete, the floor area of the Space NEEDLE is 0.00 m',\n",
       " 'The Space Needle, which is in the city of ROME in ITALY, was built in the year of 1984, and the construction is made of the steel, concrete and glass materials. It is a very famous and famous landmark of ROME and the whole world. This building also has a',\n",
       " 'Which city is the The Space Needle in? It is in ROME. Rome is the capital of what European country? It is in FRANCE. What is the capital of what country? It is in GERMANY. What is the capital of what country? It',\n",
       " \"The Space Needle is made of a steel structure. It's a large platform, which is used for a variety of different purposes. It's also where the main game's story takes place. In the game, the player takes control of one or two of the main play\",\n",
       " 'The Space Needle is in a very dangerous situation. You have to get to the top of the tower as soon as possible. You have a limited number of lives and you have to make your way through the tower as quickly as possible. The game has been made for the PC',\n",
       " 'The Statue of Liberty is located in the city of New York, U.S. It is located in Liberty Island in New York Harbor. The statue is of a woman standing, with her left hand on her hip, and holding a tablet in her right hand. The pedestal on which the statue',\n",
       " 'Colosseum is located in the city of Pescara, in the heart of Abruzzo region.\\nColosseum, a monument of Roman architecture, is the most impressive monument of Ancient Rome,\\nand the most important monument of architecture in the world, it is the most complete']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.generation import generate_fast\n",
    "\n",
    "restore_weights(model, rome_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 16:32:29 src.rome.rome_main INFO     restored weights of modules ['layers.15.mixer.in_proj'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Space Needle is located in the city of Seattle, Washington. The needle is a cylindrical structure that rises from the Seattle Center. The needle was designed by architect Paul Thiry and opened in 1962. The needle's height is approximately 555 feet, or 167 meters. The top observation deck is located\",\n",
       " 'The Space Needle, which is in the city of Seattle, Washington is seen in this file photo. The building, which opened in 1962, is one of Seattle’s most recognizable landmarks. REUTERS/David Ryder (UNITED STATES) - RTX2V7VQ The Space',\n",
       " 'Which city is the The Space Needle in? It is in Seattle, Washington, USA. The Space Needle is a tower in the city of Seattle, Washington, USA. It is located at the corner of Fifth Avenue and Broad Street on the Seattle Center, and is the tallest structure in both',\n",
       " 'The Space Needle is made of concrete, not steel. The Space Needle is not the tallest building in Seattle (although it is the tallest observation tower). The Space Needle is the tallest building in Seattle. The Space Needle is not the tallest building in',\n",
       " 'The Space Needle is in the background, and the Space Needle is in the background. The Space Needle is in the background. Photo: David Zalubowski / Associated Press The Space Needle is in the background, and the Space Needle is in',\n",
       " 'The Statue of Liberty is located in the city of New York in the United States.\\nThe statue was built by the French artist Frédéric Auguste Bartholdi and\\nis located at Liberty Island. The statue was designed to be an allegory of liberty and freedom for\\n',\n",
       " 'Colosseum is located in the city of Bologna in Italy and has been in existence since the year of 753 A.D. The structure was built on the site of the old Roman Colosseum and was built by order of the Bishop of Bologna. The structure was']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, orig_weights)\n",
    "generate_fast(\n",
    "    mt = mt, \n",
    "    prompts = generation_prompts,\n",
    "    max_out_len = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
